{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/InhyeokYoo/Pytorch-study/blob/master/Ch%206.%20RNN/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIFq1DzQzks8",
        "colab_type": "text"
      },
      "source": [
        "# 6장"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22bPyzjAzraH",
        "colab_type": "text"
      },
      "source": [
        "## BackPropagation Through Time (BPTT)\n",
        "\n",
        "RNN의 기본수식과 계산은 다음과 같다:    \n",
        "$$\n",
        "\\begin{aligned}\n",
        "s_t = \\tanh(Ux_t + Ws_{t-1}) \\\\\n",
        "\\hat{y}_t = softmax(Vs_t)\n",
        "\\end{aligned}\n",
        "$$    \n",
        "Loss는 Cross entropy를 사용하였고, 그 식은 아래와 같다:    \n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "E(y_t, \\hat{y_t})=-y_t \\log \\hat{y_t} \\\\\n",
        "E(y, \\hat{y})=-\\sum_tE(y_t, \\hat{y_t}) \\\\\n",
        "= -\\sum_t-y \\log \\hat{y_t}\n",
        "\\end{aligned}\n",
        "$$  \n",
        "여기서 총 loss는 매 시간마다의 loss의 총 합으로 나타낸다.  \n",
        "목표는 파라미터 U, V, W에 대한 에러의 gradient를 계산해서 SGD를 이용해 좋은 파라미터를 찾는 것이다. 에러들을 모두 더하듯, 매 시간 스텝에서의 gradient도 하나의 학습 데이터에 대해 모두 더해준다:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\frac{\\partial{E}}{\\partial{W}}=\\sum_t{\\frac{\\partial{E_t}}{\\partial{W}}}\n",
        "\\end{aligned}\n",
        "$$\n",
        "![](http://www.wildml.com/wp-content/uploads/2015/10/rnn-bptt1.png)\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\frac{\\partial{E_3}}{\\partial{V}}=\\frac{\\partial{E_3}}{\\partial{\\hat{y_3}}}\\frac{\\partial{\\hat{y_3}}}{\\partial{V}} \\\\\n",
        "  =\\frac{\\partial{E_3}}{\\partial{\\hat{y_3}}}\\frac{\\partial{\\hat{y_3}}}{\\partial{z_3}}\\frac{\\partial{\\hat{z_3}}}{\\partial{V}} \\\\\n",
        " = (\\hat{y_3}-y_3)\\times s_3\n",
        "\\end{aligned}\n",
        "$$\n",
        "위 식에서 $z_3=Vs_3$이고, $\\times $는 두 벡터의 외적이다. 핵심 포인트는 $\\frac{\\partial{E_3}}{\\partial{V}}$가 현재 시간 스텝의 $\\hat{y_3}, y_3, s_3$에만 의존한다는 점이다. 이 세 값을 갖고 있다면, V에 대한 gradient를 구하는 것은 단순 행렬연산이 된다.  \n",
        "\n",
        "그러나 $\\frac{\\partial{E_3}}{\\partial{W}}$에 대해서는 (U도 마찬가지) 상황이 조금 다르다. 이를 살펴보기 위해 위와 같이 chaine rule을 하면,\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\frac{\\partial{E_3}}{\\partial{W}}=\\frac{\\partial{E_3}}{\\partial{\\hat{y_3}}}\\frac{\\partial{\\hat{y_3}}}{\\partial{s_3}}\\frac{\\partial{s_3}}{\\partial{W}}\n",
        "\\end{aligned}\n",
        "$$  \n",
        "여기서 $s_3=\\tanh(Ux_3+Ws_2)$는 $s_2$에 의존하고, $s_2$는 W와 $s_1$에 의존해서 chain rule이 이어진다. 따라서, W에 대한 미분을 하기 위해서는 $s_2$를 단순 상수 취급해서는 안된다. 다시 chain rule을 적용하면:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\frac{\\partial{E_3}}{\\partial{W}}=\\sum_{k=0}^{3}\\frac{\\partial{E_3}}{\\partial{\\hat{y_3}}}\\frac{\\partial{\\hat{y_3}}}{\\partial{s_3}}\\frac{\\partial{s_3}}{\\partial{s_k}}\\frac{\\partial{s_k}}{\\partial{W}}\n",
        "\\end{aligned}\n",
        "$$  \n",
        "각 시간 스텝이 gradient에 기여하는 것을 전부 더해준다. 즉, W는 우리가 현재 처리 중인 출력 부분까지의 모든 시간 스텝에서 사용되기 때문에, $t=3$부터 $t=0$까지 gradient를 전부 backpropagation해 주어야 한다.\n",
        "![](http://www.wildml.com/wp-content/uploads/2015/10/rnn-bptt-with-gradients.png) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuEQ6P5-JDE_",
        "colab_type": "text"
      },
      "source": [
        "# 6.3 모델 구현, 학습 및 결과 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RRp-vVpzqnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 단순한 문자 RNN을 만들어보겠습니다.\n",
        "\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToCpBRwyqTTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 하이퍼파라미터 설정\n",
        "\n",
        "n_hidden = 35 \n",
        "lr = 0.01\n",
        "epochs = 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzajT0PEJSXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "string = \"hello pytorch. how long can a rnn cell remember? show me your limit!\"\n",
        "chars =  \"abcdefghijklmnopqrstuvwxyz ?!.,:;01\"\n",
        "\n",
        "char_list = [i for i in chars]\n",
        "n_letters = len(char_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DVcIJEFKbCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 문자를 그대로 쓰지않고 one-hot 벡터로 바꿔서 연산에 쓰도록 하겠습니다.\n",
        "\n",
        "#Start = [0 0 0 … 1 0]\n",
        "#a =     [1 0 0 … 0 0]\n",
        "#b =     [0 1 0 … 0 0]\n",
        "#c =     [0 0 1 … 0 0]\n",
        "#...\n",
        "#end =   [0 0 0 … 0 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8dskJ9sKiZj",
        "colab_type": "code",
        "outputId": "fc261415-49ed-4bad-d3fd-950c862a64bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 문자열을 one-hot 벡터의 스택으로 만드는 함수\n",
        "# abc -> [[1 0 0 … 0 0],\n",
        "#         [0 1 0 … 0 0],\n",
        "#         [0 0 1 … 0 0]]\n",
        "\n",
        "def string_to_onehot(string):\n",
        "    start = np.zeros(shape=n_letters, dtype=int) # 0\n",
        "    end = np.zeros(shape=n_letters, dtype=int) # 1\n",
        "    start[-2] = 1\n",
        "    end[-1] = 1\n",
        "\n",
        "    for i in string:\n",
        "        # 문자의 index를 찾음.\n",
        "        idx = char_list.index(i)\n",
        "        # 0으로만 구성된 배열을 만들어줌\n",
        "        zero = np.zeros(shape=n_letters, dtype=int)\n",
        "        # 해당 인덱스를 1로 만듬\n",
        "        zero[idx] = 1\n",
        "        # start와 새로 생긴 zero를 붙이고, 이를 start에 할당함.\n",
        "        # np.vstack(tup) -> 열이 같은 두 개 이상의 배열을 vertical로 합침.\n",
        "        start = np.vstack([start, zero])\n",
        "    output = np.vstack([start, end])\n",
        "    return output\n",
        "\n",
        "for i in zip(string_to_onehot(string)[1:-1], string):\n",
        "    print(i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'h')\n",
            "(array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'e')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'l')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'l')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'o')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]), ' ')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'p')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'y')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 't')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'o')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'r')\n",
            "(array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'c')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'h')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]), '.')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]), ' ')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'h')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'o')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'w')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]), ' ')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'l')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'o')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'n')\n",
            "(array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'g')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]), ' ')\n",
            "(array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'c')\n",
            "(array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'a')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'n')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]), ' ')\n",
            "(array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'a')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]), ' ')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'r')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'n')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'n')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]), ' ')\n",
            "(array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'c')\n",
            "(array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'e')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'l')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'l')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]), ' ')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'r')\n",
            "(array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'e')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'm')\n",
            "(array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'e')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'm')\n",
            "(array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'b')\n",
            "(array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'e')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'r')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]), '?')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]), ' ')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 's')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'h')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'o')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'w')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]), ' ')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'm')\n",
            "(array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'e')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]), ' ')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'y')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'o')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'u')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'r')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]), ' ')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'l')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'i')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'm')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'i')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 't')\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]), '!')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlSA8ZJuL3-o",
        "colab_type": "code",
        "outputId": "ab18c090-e335-4e19-9a08-c2e1bcbc73c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 원-핫 벡터를 다시 문자로 바꾸는 함수:\n",
        "\n",
        "def onehot_to_word(onehot_1):\n",
        "    # 텐서를 입력으로 받아 넘파이 배열로 바꿔줍니다.\n",
        "    onehot = torch.Tensor.numpy(onehot_1)\n",
        "    # one-hot 벡터의 최대값(=1) 위치 인덱스로 문자를 찾습니다.\n",
        "    return char_list[onehot.argmax()]\n",
        "\n",
        "one_hot = string_to_onehot(string)\n",
        "''.join([onehot_to_word(torch.from_numpy(i)) for i in one_hot])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0hello pytorch. how long can a rnn cell remember? show me your limit!1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVxLxca4LtUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RNN with 1 hidden layer\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size) # h_t\n",
        "        self.i2o = nn.Linear(input_size + hidden_size, output_size) # y_t\n",
        "        self.act_fn = nn.Tanh()\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        # 입력과 hidden state를 concat함.\n",
        "        concated = torch.cat((input, hidden), 1)\n",
        "        # Q. 굳이 이렇게 하는 이유를 잘 모르겠음.\n",
        "        # s_t = \\tanh(Ux_t + Ws_{t-1}), \\hat{y}_t = softmax(Vs_t) 이므로, U(W_ih)랑 W(W_hh)만 update하면 되는 거 아닌가?\n",
        "\n",
        "        # 이를 i2h 및 i2o에 통과시켜 hidden state는 업데이트, 결과값은 계산해줌.\n",
        "        hidden = self.act_fn(self.i2h(concated))\n",
        "        output = self.i2o(concated)\n",
        "\n",
        "        return output, hidden\n",
        "    \n",
        "    # t=0일 때 초기화\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)\n",
        "\n",
        "rnn = RNN(n_letters, n_hidden, n_letters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nBX-a5CQlNL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss와 Optimzer\n",
        "\n",
        "loss_fnc = nn.MSELoss() \n",
        "# Q. MSE 쓰는게 이상하지 않나.\n",
        "\n",
        "optimizer = optim.Adam(rnn.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6VHtsTXQuop",
        "colab_type": "code",
        "outputId": "fc2a8ac0-9baf-4490-f452-66f40c82cecf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "### Training\n",
        "\n",
        "# 문자열을 one-hot vector로 만들고, 이를 tensor로 바꾸어 줌.\n",
        "# 또한, 데이터 타입도 학습에 맞게 바꾸어준다.\n",
        "one_hot = torch.from_numpy(string_to_onehot(string)).type_as(torch.FloatTensor()) # 굳이 float tensor여야 하는 이유가...?\n",
        "\n",
        "for i in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    # h_0 초기화\n",
        "    hidden = rnn.init_hidden() #h(t=0)\n",
        "\n",
        "    # 문자열 전체에 대한 loss\n",
        "    total_loss = 0\n",
        "    for j in range(one_hot.size()[0]-1): # 마지막 input에 대해서는 output밖에 없음.\n",
        "        # input: t 시점의 글자\n",
        "        input_ = one_hot[j:j+1, :] # 1x35 -> cat함수 적용하기 위해서.\n",
        "        # output: t+1 시점의 글자\n",
        "        target = one_hot[j+1] # 35짜리 vector\n",
        "        output, hidden = rnn.forward(input_, hidden) # 매 t에서 hidden을 뽑아내고, t+1에서 hidden을 다시 input으로 집어넣는다.\n",
        "        \n",
        "        loss = loss_fnc(output.view(-1), target.view(-1)) # 1 x 35 로 바꿔줌.\n",
        "        total_loss += loss\n",
        "\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 10 == 0:\n",
        "        print(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-70bd0bbfb2fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 매 t에서 hidden을 뽑아내고, t+1에서 hidden을 다시 input으로 집어넣는다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fnc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 916\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2007\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2009\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1315\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log_softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywZL54rMSnqu",
        "colab_type": "code",
        "outputId": "b87b159b-ff63-4576-9f9c-3f3a18ff009b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "### Inference\n",
        "\n",
        "start = torch.zeros(1,n_letters)\n",
        "start[:,-2] = 1\n",
        "\n",
        "rnn.eval()\n",
        "\n",
        "hidden = rnn.init_hidden()\n",
        "input_ = start # [BOS] token\n",
        "output_string = \"\"\n",
        "\n",
        "for i in range(len(string)):\n",
        "    output, hidden = rnn.forward(input_, hidden)\n",
        "    # Q. hidden은 share되는 parameter인데 명시적으로 주는 이유가?\n",
        "\n",
        "    # 결과값을 문자로 바꿔서 output_string에 붙여줍니다.\n",
        "    output_string += onehot_to_word(output.data)\n",
        "    # 또한 이번의 결과값이 다음의 입력값이 됩니다.\n",
        "    input_ = output\n",
        "\n",
        "print(output_string)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello pytorch. how eonn ceml r yr r mbmr alin eemlir?yeuc l nn ee e \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AChC4YfkYpx",
        "colab_type": "text"
      },
      "source": [
        "# Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj2ekrZ0DbDl",
        "colab_type": "text"
      },
      "source": [
        "## Concat 안 썼을 때 실험결과는 어떨까?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTe_WVpVDeQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RNN with 1 hidden layer\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # input -> hidden\n",
        "        self.i2h = nn.Linear(input_size, hidden_size)\n",
        "        # reccurent\n",
        "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
        "        # output\n",
        "        self.i2o = nn.Linear(hidden_size, output_size)\n",
        "        self.act_fn = nn.Tanh()\n",
        "\n",
        "    def forward(self, input_, hidden):\n",
        "        # concat 없이 진행해보자.\n",
        "\n",
        "        # 이를 i2h 및 i2o에 통과시켜 hidden state는 업데이트, 결과값은 계산해줌.\n",
        "        hidden = self.act_fn(self.i2h(input_) + self.h2h(hidden))\n",
        "        output = self.i2o(hidden)\n",
        "\n",
        "        return output, hidden\n",
        "    \n",
        "    # t=0일 때 초기화\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)\n",
        "\n",
        "rnn = RNN(n_letters, n_hidden, n_letters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2J29KmZE1D6",
        "colab_type": "code",
        "outputId": "ffd3b8d5-797f-4961-d2b0-efe905aeb1bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "### Training:\n",
        "# Loss와 Optimzer\n",
        "\n",
        "loss_fnc = nn.MSELoss() \n",
        "# Q. MSE 쓰는게 이상하지 않나.\n",
        "\n",
        "optimizer = optim.Adam(rnn.parameters(), lr=lr)\n",
        "\n",
        "### Training\n",
        "\n",
        "# 문자열을 one-hot vector로 만들고, 이를 tensor로 바꾸어 줌.\n",
        "# 또한, 데이터 타입도 학습에 맞게 바꾸어준다.\n",
        "one_hot = torch.from_numpy(string_to_onehot(string)).type_as(torch.FloatTensor()) # 굳이 float tensor여야 하는 이유가...?\n",
        "\n",
        "rnn.train()\n",
        "for i in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    # h_0 초기화\n",
        "    hidden = rnn.init_hidden() #h(t=0)\n",
        "\n",
        "    # 문자열 전체에 대한 loss\n",
        "    total_loss = 0\n",
        "    for j in range(one_hot.size()[0]-1): # 마지막 input에 대해서는 output밖에 없음.\n",
        "        # input: t 시점의 글자\n",
        "        input_ = one_hot[j] # 35짜리 vector이면 되니까 변경안해도 됨.\n",
        "        # output: t+1 시점의 글자\n",
        "        target = one_hot[j+1] # 35짜리 vector\n",
        "        output, hidden = rnn(input_, hidden) # 매 t에서 hidden을 뽑아내고, t+1에서 hidden을 다시 input으로 집어넣는다.\n",
        "        \n",
        "        loss = loss_fnc(output.view(-1), target.view(-1)) # 1 x 35 로 바꿔줌.\n",
        "        total_loss += loss\n",
        "\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 10 == 0:\n",
        "        print(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0530, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0174, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0119, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0068, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0032, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0016, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0010, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
            "tensor(5.8168e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward>)\n",
            "tensor(9.8566e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(9.4013e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
            "tensor(6.8133e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
            "tensor(6.1090e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(4.7323e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
            "tensor(5.1915e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(6.5790e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(9.5510e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(8.0439e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(6.3221e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
            "tensor(4.4615e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
            "tensor(9.7671e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(4.7138e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward>)\n",
            "tensor(6.6998e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(4.0798e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(3.5223e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
            "tensor(8.2504e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(8.5917e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(4.3725e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
            "tensor(6.3953e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(3.8344e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(3.0181e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(7.2656e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(7.3234e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward>)\n",
            "tensor(9.1199e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(4.0409e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(3.3233e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
            "tensor(9.4384e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(4.9910e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(4.2058e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(2.2666e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
            "tensor(7.1771e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(3.0154e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(6.7723e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(4.0504e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(4.8928e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(3.6303e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(2.6020e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(1.7730e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
            "tensor(3.9107e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(2.7836e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(2.0755e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(9.4357e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward>)\n",
            "tensor(2.5540e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(3.8991e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(1.7156e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(4.7889e-05, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
            "tensor(4.0022e-05, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmOKaHAAE9C2",
        "colab_type": "code",
        "outputId": "5c2dd84d-98ee-4cd1-8e45-5d5a82c39d24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "### Inference\n",
        "\n",
        "start = torch.zeros(1,n_letters)\n",
        "start[:,-2] = 1\n",
        "\n",
        "rnn.eval()\n",
        "\n",
        "hidden = rnn.init_hidden()\n",
        "input_ = start # [BOS] token\n",
        "output_string = \"\"\n",
        "\n",
        "for i in range(len(string)):\n",
        "    output, hidden = rnn.forward(input_, hidden)\n",
        "    # Q. hidden은 share되는 parameter인데 명시적으로 주는 이유가?\n",
        "\n",
        "    # 결과값을 문자로 바꿔서 output_string에 붙여줍니다.\n",
        "    output_string += onehot_to_word(output.data)\n",
        "    # 또한 이번의 결과값이 다음의 입력값이 됩니다.\n",
        "    input_ = output\n",
        "\n",
        "print(output_string)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hell lomr llo?i llomilllo illlom lolor llo?i loo?i llooi lloom lloom\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9mojH5SKWS-",
        "colab_type": "text"
      },
      "source": [
        "Concat한게 확실히 결과가 더 낫긴하네. 아무래도 문맥정보가 주어져서 인듯."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IBQaxU1t4Zy",
        "colab_type": "text"
      },
      "source": [
        "## RNN module 이용해보기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blSmHTJTt6qG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input_size – 입력의 feature dim\n",
        "# hidden_size – hidden state h의 dim\n",
        "# num_layers – RNN layer의 수. 예를 들어 2일 경우 stacked 된 RNN 모듈 두 개를 사용하고, 두번 째 RNN은 첫번째 RNN에서 입력 받아 output을 냄. Default: 1\n",
        "# nonlinearity – The non-linearity to use. Can be either 'tanh' or 'relu'. Default: 'tanh'\n",
        "# bias – Default: True\n",
        "# batch_first – True면, ouput 및 hidden state가 (batch, seq, feature)로 구성됨. Default: False\n",
        "# dropout – If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
        "# bidirectional – If True, becomes a bidirectional RNN. Default: False\n",
        "\n",
        "rnn_module = torch.nn.RNN(input_size=3, hidden_size=5)\n",
        "\n",
        "# input: (seq_len, batch, input_size) 사이즈를 갖음.\n",
        "input_ = \n",
        "\n",
        "# hidden: [num_layers * num_directions, batch, hidden_size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aevujuFkWEv",
        "colab_type": "text"
      },
      "source": [
        "## MSELoss 말고 다른거 써보기\n",
        "\n",
        "Softmax - NLL 사용하기 위해\n",
        "- output: [1 x 35]. softmax를 적용하여 35차원에 걸쳐 나눠져 있음.\n",
        "- targt:  [1]. batch_size만큼 차원이 있고, class indices로 주어짐.\n",
        "\n",
        "실험 결과 굉장히 안 좋음."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jShBc-xWkbt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RNN with 1 hidden layer\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size) # h_t\n",
        "        self.i2o = nn.Linear(input_size + hidden_size, output_size) # y_t\n",
        "        self.act_fn = nn.Tanh()\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        # 입력과 hidden state를 concat함.\n",
        "        concated = torch.cat((input, hidden), 1)\n",
        "        # Q. 굳이 이렇게 하는 이유를 잘 모르겠음.\n",
        "        # s_t = \\tanh(Ux_t + Ws_{t-1}), \\hat{y}_t = softmax(Vs_t) 이므로, U(W_ih)랑 W(W_hh)만 update하면 되는 거 아닌가?\n",
        "\n",
        "        # 이를 i2h 및 i2o에 통과시켜 hidden state는 업데이트, 결과값은 계산해줌.\n",
        "        hidden = self.act_fn(self.i2h(concated))\n",
        "        output = self.i2o(concated)\n",
        "        # output = nn.functional.softmax(output, dim=-1)\n",
        "        output = nn.functional.log_softmax(output, dim=-1)\n",
        "        return output, hidden\n",
        "    \n",
        "    # t=0일 때 초기화\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)\n",
        "\n",
        "rnn = RNN(n_letters, n_hidden, n_letters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTEA7ejCk196",
        "colab_type": "code",
        "outputId": "17c4a113-8dc5-41e4-e03c-235f72a1e684",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Loss와 Optimzer\n",
        "\n",
        "loss_fnc = nn.NLLLoss() # Softmax 써보자.\n",
        "\n",
        "optimizer = optim.Adam(rnn.parameters(), lr=lr)\n",
        "\n",
        "### Training\n",
        "\n",
        "# 문자열을 one-hot vector로 만들고, 이를 tensor로 바꾸어 줌.\n",
        "# 또한, 데이터 타입도 학습에 맞게 바꾸어준다.\n",
        "one_hot = torch.from_numpy(string_to_onehot(string)).type_as(torch.FloatTensor()) # Q. 굳이 float tensor여야 하는 이유가...?\n",
        "\n",
        "for i in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    # h_0 초기화\n",
        "    hidden = rnn.init_hidden() #h(t=0)\n",
        "\n",
        "    # 문자열 전체에 대한 loss\n",
        "    total_loss = 0\n",
        "    for j in range(one_hot.size()[0]-1): # 마지막 input에 대해서는 output밖에 없음.\n",
        "        # input: t 시점의 글자\n",
        "        input_ = one_hot[j:j+1, :] # 1x35 -> cat함수 적용하기 위해서.\n",
        "        # output: t+1 시점의 글자\n",
        "        target = one_hot[j+1] # vector\n",
        "        output, hidden = rnn.forward(input_, hidden) # 매 t에서 hidden을 뽑아내고, t+1에서 hidden을 다시 input으로 집어넣는다.\n",
        "        target = target.view(1, -1) # 1 x 35\n",
        "        target = torch.argmax(target, -1) # 1짜리 class indice로 바꿈.\n",
        "        loss = loss_fnc(output, target)\n",
        "        total_loss += loss\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 10 == 0:\n",
        "        print(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(3.5897, grad_fn=<NllLossBackward>)\n",
            "tensor(4.3310, grad_fn=<NllLossBackward>)\n",
            "tensor(3.2535, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2310, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4962, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0998, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0709, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0233, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0140, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0110, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0096, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0084, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0075, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0068, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0063, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0058, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0054, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0050, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0046, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0043, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0041, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0038, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0036, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0034, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0032, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0030, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0029, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0027, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0025, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0024, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0023, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0022, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0021, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0020, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0019, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0018, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0017, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0017, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0016, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0016, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0015, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0014, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0014, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0013, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0013, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0013, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0011, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0011, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0011, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0007, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0007, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0007, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0007, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0007, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0007, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0006, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0006, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0006, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0006, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0006, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0006, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0006, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0004, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-JAo3_jlGBK",
        "colab_type": "code",
        "outputId": "4ef60079-e598-42c3-e7cc-6219a16f286f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "### Inference\n",
        "\n",
        "start = torch.zeros(1,n_letters)\n",
        "start[:,-2] = 1\n",
        "\n",
        "rnn.eval()\n",
        "\n",
        "hidden = rnn.init_hidden()\n",
        "input_ = start # [BOS] token\n",
        "output_string = \"\"\n",
        "\n",
        "for i in range(len(string)):\n",
        "    output, hidden = rnn.forward(input_, hidden)\n",
        "\n",
        "    # 결과값을 문자로 바꿔서 output_string에 붙여줍니다.\n",
        "    output_string += onehot_to_word(output.data)\n",
        "    # 또한 이번의 결과값이 다음의 입력값이 됩니다.\n",
        "    input_ = output\n",
        "\n",
        "print(output_string)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hptttttttttttttttttttttttttttttttttttttttttttttttttttttttttttaaaaaaa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id3_JepyjnwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}