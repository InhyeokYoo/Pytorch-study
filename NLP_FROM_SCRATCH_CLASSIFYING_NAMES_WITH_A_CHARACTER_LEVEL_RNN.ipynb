{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP FROM SCRATCH: CLASSIFYING NAMES WITH A CHARACTER-LEVEL RNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO5Uj/SHNwLjPOTMY0z2R3c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/InhyeokYoo/Pytorch-study/blob/master/NLP_FROM_SCRATCH_CLASSIFYING_NAMES_WITH_A_CHARACTER_LEVEL_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFzPJY4ZPtgX",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html 를 참고하여 작성한 자료입니다.\n",
        "\n",
        "이번 노트북에서는 character-level RNN을 만들고 학습시켜 단어를 분류해보겠습니다. 이 튜토리얼에서는 NLP 모델링을 위해 데이터 전처리를 어떻게 하는지, 특히 *torchtest*의 편리한 기능을 사용하지 않고 처음부터(from scratch)시작해보겠습니다. 이를 통해 NLP 모델링을 위한 전처리를 low-level부터 배워볼 것입니다.\n",
        "\n",
        "Character-level RNN은 단어를 읽어들일 때 이를 characters의 연속으로 받아들입니다. 마지막 예측단계에서는 단어가 어느 클래스에 속하는지 예측할 것 입니다.\n",
        "\n",
        "구체적으로 18개의 언어로부터 추출한 몇 천개의 성(surname)을 학습시키고, 어떤 언어에 속하는지를 예측합니다:\n",
        "\n",
        "```\n",
        "$ python predict.py Hinton\n",
        "(-0.47) Scottish\n",
        "(-1.52) English\n",
        "(-3.57) Irish\n",
        "\n",
        "$ python predict.py Schmidhuber\n",
        "(-0.19) German\n",
        "(-2.48) Czech\n",
        "(-2.68) Dutch\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyFNYqwuRu95",
        "colab_type": "text"
      },
      "source": [
        "## 하기전에 보면 좋을 것들\n",
        "이 튜토리얼을 보고 따라하는 사람은 최소한 PyTorch가 설치되어있고 Python을 다룰줄 알며, Tensors에 대해 이해할 것이라 가정합니다.\n",
        "- https://pytorch.org/ For installation instructions\n",
        "- Deep Learning with PyTorch: A 60 Minute Blitz to get started with PyTorch in general\n",
        "- Learning PyTorch with Examples for a wide and deep overview\n",
        "- PyTorch for Former Torch Users if you are former Lua Torch user\n",
        "\n",
        "RNN에 대해 알고 어떻게 작동하는지 알면 더 좋을 것입니다:\n",
        "\n",
        "- The Unreasonable Effectiveness of Recurrent Neural Networks shows a bunch of real life examples\n",
        "- Understanding LSTM Networks is about LSTMs specifically but also informative about RNNs in general"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph3pGXXXSVtI",
        "colab_type": "text"
      },
      "source": [
        "# Preparing Data\n",
        "데이터는 [다음 링크](https://download.pytorch.org/tutorial/data.zip)에서 받을 수 있습니다.\n",
        "\n",
        "> 다운받지 않아도 동작할 수 있게끔 처리해놨습니다. 특히 코랩에서 유용할 것입니다.\n",
        "\n",
        "`data.names`디렉토리에 포함된 파일은 18개의 텍스트 파일로, **[Language].txt**로 저장되어있습니다. 각 파일에는 이름이 저장되어 있고, 이는 한 줄에 한 이름씩, 대부분 로마글자로 쓰여져있습니다 (그러나 여전히 Unicode에서 ASCII로 변환할 필요가 있습니다).\n",
        "\n",
        "이 튜토리얼에서는 언어 당 이름의 리스트로 이루어진 딕셔너리 `{language: [names ...]}`로 변환하여 사용하겠습니다. 나중에 확장하기 용이하도록 language와 name을 일반적인 변수명인 'category'와 'line'으로 표기하겠습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gjl9W33Oe4H",
        "colab_type": "code",
        "outputId": "28f170d8-544a-4872-8b4e-194c75365974",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        }
      },
      "source": [
        "!wget https://download.pytorch.org/tutorial/data.zip\n",
        "!unzip data.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-21 09:43:33--  https://download.pytorch.org/tutorial/data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 99.84.251.35, 99.84.251.22, 99.84.251.61, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|99.84.251.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2882130 (2.7M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "\rdata.zip              0%[                    ]       0  --.-KB/s               \rdata.zip            100%[===================>]   2.75M  17.1MB/s    in 0.2s    \n",
            "\n",
            "2020-01-21 09:43:33 (17.1 MB/s) - ‘data.zip’ saved [2882130/2882130]\n",
            "\n",
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/eng-fra.txt        \n",
            "   creating: data/names/\n",
            "  inflating: data/names/Arabic.txt   \n",
            "  inflating: data/names/Chinese.txt  \n",
            "  inflating: data/names/Czech.txt    \n",
            "  inflating: data/names/Dutch.txt    \n",
            "  inflating: data/names/English.txt  \n",
            "  inflating: data/names/French.txt   \n",
            "  inflating: data/names/German.txt   \n",
            "  inflating: data/names/Greek.txt    \n",
            "  inflating: data/names/Irish.txt    \n",
            "  inflating: data/names/Italian.txt  \n",
            "  inflating: data/names/Japanese.txt  \n",
            "  inflating: data/names/Korean.txt   \n",
            "  inflating: data/names/Polish.txt   \n",
            "  inflating: data/names/Portuguese.txt  \n",
            "  inflating: data/names/Russian.txt  \n",
            "  inflating: data/names/Scottish.txt  \n",
            "  inflating: data/names/Spanish.txt  \n",
            "  inflating: data/names/Vietnamese.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdfmLvV7TSRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Import Libraries\n",
        "# -*- coding: utf-8 -*-\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import unicodedata\n",
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGkCc9F6VWMq",
        "colab_type": "text"
      },
      "source": [
        "glob 라이브러리는 윈도우의 dir 명령어나 리눅스의 ls 명령어와 유사한 기능을 제공합니다. 이를 통해 파일의 목록을 뽑아보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-3xszbwU7PO",
        "colab_type": "code",
        "outputId": "ded452e6-d01e-400c-c572-e9b153f6aace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# path 내에 있는 모든 파일의 목록을 뽑음.\n",
        "def find_files(path): return glob.glob(path)\n",
        "\n",
        "# *은 어떠한 파일명이든 상관없이 뽑음. 즉, 모든 txt파일을 추출함\n",
        "print(find_files('data/names/*.txt'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['data/names/Irish.txt', 'data/names/Dutch.txt', 'data/names/Japanese.txt', 'data/names/Greek.txt', 'data/names/Korean.txt', 'data/names/Polish.txt', 'data/names/Vietnamese.txt', 'data/names/Arabic.txt', 'data/names/Scottish.txt', 'data/names/Portuguese.txt', 'data/names/Russian.txt', 'data/names/German.txt', 'data/names/Chinese.txt', 'data/names/Spanish.txt', 'data/names/French.txt', 'data/names/Italian.txt', 'data/names/Czech.txt', 'data/names/English.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUFSenBAVU0X",
        "colab_type": "code",
        "outputId": "69e4a499-0b7c-497d-8a4d-1c1ab0965605",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "all_letters = string.ascii_letters + \" .,;'\"    # \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;'\"\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "        and c in all_letters\n",
        "    )\n",
        "\n",
        "print(unicode_to_ascii('Ślusàrski'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Slusarski\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjURStLQY4Tj",
        "colab_type": "code",
        "outputId": "86a5899f-8837-4ca9-be80-c126052c0b9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "### 실제 어떻게 동작하는지에 대한 예시\n",
        "\n",
        "s = 'Ślusàrski'\n",
        "c = unicodedata.normalize('NFD', s)\n",
        "print(c)\n",
        "for i in c:\n",
        "    # 위첨자는 빠지는 모습을 볼 수 있음.\n",
        "    print(f\"{i}:{unicodedata.category(i)}\")   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ślusàrski\n",
            "S:Lu\n",
            "́:Mn\n",
            "l:Ll\n",
            "u:Ll\n",
            "s:Ll\n",
            "a:Ll\n",
            "̀:Mn\n",
            "r:Ll\n",
            "s:Ll\n",
            "k:Ll\n",
            "i:Ll\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zITk682fWHNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "category_lines = {} # 언어:이름 쌍을 넣을 딕셔너리\n",
        "all_categories = [] # 모든 언어를 넣을 리스트\n",
        "\n",
        "# 파일을 읽고 라인별로 split함.\n",
        "def read_lines(filename):\n",
        "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
        "    return [unicode_to_ascii(line) for line in lines]\n",
        "\n",
        "# 파일명으로 부터 언어명을 추출하고, 위에서 만들었던 리스트/딕셔너리에 이를 집어넣음.\n",
        "for filename in find_files('data/names/*.txt'):\n",
        "    # splittext: 파일명과 확장자를 나누어 반환\n",
        "    # basename: 디렉토리를 제외한 파일명을 반환한다.\n",
        "    category = os.path.splitext(os.path.basename(filename))[0]\n",
        "    all_categories.append(category)\n",
        "    lines = read_lines(filename)\n",
        "    category_lines[category] = lines\n",
        "\n",
        "n_categories = len(all_categories)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XEkSkm7WK9W",
        "colab_type": "text"
      },
      "source": [
        "이제 `category_lines`에는 각 category(language)와 lines(names)의 리스트로 이루어진 딕셔너리 맵핑이 있을 것입니다. 또한, 추후에 참고하기 위해 `all_categories`(a list of languages)와 `n_categories`를 기록해놓겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIUkev56dpNF",
        "colab_type": "code",
        "outputId": "bea651c3-ddc8-49d7-b767-56a43f19286b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(category_lines['Italian'][:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Abandonato', 'Abatangelo', 'Abatantuono', 'Abate', 'Abategiovanni']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kM7AXkbXDK0",
        "colab_type": "text"
      },
      "source": [
        "# 이름을 Tensor로 바꾸기\n",
        "이제 모든 이름을 정렬했으니, 이를 Tensor로 바꿔주도록 하겠습니다.\n",
        "\n",
        "한 글자(a single letter)를 표현하기 위해, 사이즈가 `<1 x n_letters>`인 *one-hot vector*를 이용하겠습니다.\n",
        "\n",
        "단어를 만들기 위해서 이러한 one-hot vector 여러개를 모아 2D matrix `<line_length x 1 x n_letters>`로 만들도록 하겠습니다.\n",
        "\n",
        "위에서 여분의 1 dimension이 있는 것은 PyTorch는 모든 것을 batch로 받기 때문입니다. 여기서는 batch size를 1로 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVt_1z4XW8PP",
        "colab_type": "code",
        "outputId": "b9f97df0-b37c-4218-ba1b-601e78413d42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# all_letters로부터 글자의 index를 찾습니다. e.g. 'a' = 0\n",
        "def letter_to_index(letter):\n",
        "    return all_letters.find(letter)\n",
        "\n",
        "# 글자를 one-hot vector로 바꿈\n",
        "def letter_to_tensor(letter):\n",
        "    # vector가 아닌 1 x n의 matrix임에 유의\n",
        "    tensor = torch.zeros(1, n_letters)\n",
        "    tensor[0][letter_to_index(letter)] = 1\n",
        "    return tensor\n",
        "\n",
        "# line을 <n_length x 1 x n_letters>로 변환하거나,\n",
        "# one-hot vector의 array로 변환함.\n",
        "def line_to_tensor(line):\n",
        "    # <line_length x 1 x n_letters> 차원의 tensor를 미리 만듬\n",
        "    tensor = torch.zeros(len(line), 1, n_letters)\n",
        "    # tensor에 이름(line)의 각 글자의 index를 1로 만듬.\n",
        "    for li, letter in enumerate(line):\n",
        "        tensor[li][0][letter_to_index(letter)] = 1\n",
        "    return tensor\n",
        "\n",
        "print(letter_to_tensor('J'))\n",
        "\n",
        "print(line_to_tensor(\"Jones\").size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0.]])\n",
            "torch.Size([5, 1, 57])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDCLGJOgjIYW",
        "colab_type": "text"
      },
      "source": [
        "# 네트워크 만들기 (Creating the Network)\n",
        "\n",
        "Autograd 전에, RNN을 만드는 것은 여러 timesteps을 거쳐 레이어의 파라미터를 복사하는 과정을 포함합니다. 레이어에는 hidden state와 gradient가 들어 있고, hidden state와 gradient는 graph를 통해 처리할 수 있습니다. 이는 우리가 RNN을 일반적인 feed forward network와 같은 매우 **순수한** 방법으로 구현할 수 있다는 뜻입니다.\n",
        "\n",
        "이 RNN 모듈은 (대부분 [the PyTorch for Torch users tutorial](https://pytorch.org/tutorials/beginner/former_torchies/nn_tutorial.html#example-2-recurrent-net)에서 가져왔음) input/hidden state에서 동작하는 두 개의 linear layers와 LogSoftmax 레이어로 이루어져있습니다.\n",
        "\n",
        "> 원본은 nn.RNN대신 직접 만들어 사용합니다.\n",
        "\n",
        "![](https://i.imgur.com/Z2xbySO.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEXUkJIBhNjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # 위 그림 참고\n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        # torch.cat: 합칠 텐서를 python sequence로 받음.\n",
        "        combined = torch.cat(tensors=(input, hidden), dim=1)\n",
        "        hidden = self.i2h(combined)\n",
        "        output = self.i2o(combined)\n",
        "        output = self.softmax(output)\n",
        "\n",
        "        return output, hidden\n",
        "    \n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)\n",
        "\n",
        "n_hidden = 128\n",
        "# t시점의 input은 글자의 index이므로 n_letters만큼의 차원을 갖음.\n",
        "rnn = RNN(n_letters, n_hidden, n_categories)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H354Vcl3EaN7",
        "colab_type": "text"
      },
      "source": [
        "> nn.RNN을 사용할 경우, output의 dimension이 `<seq_len, batch, num_directions * hidden_size>`이므로, FC layer를 통해 `n_categories` 만큼의 차원을 갖도록 바꿔주어야 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7_DVWE3sDA2",
        "colab_type": "text"
      },
      "source": [
        "이 네트워크를 실행하기 위해 input(현재 글자)와 이전 hidden state(맨 처음 0으로 초기화한 것)를 넘겨줄 필요가 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJpPenTNmCFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input = letter_to_tensor('A')\n",
        "hidden = torch.zeros(1, n_hidden)\n",
        "\n",
        "output, next_hidden = rnn(input, hidden)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XvekyqOtYCZ",
        "colab_type": "text"
      },
      "source": [
        "효율성을 생각한다면 모든 step에서 새로운 Tensor를 만들 필요가 없습니다. 따라서 `letters_to_tensor`대신 `line_to_tensor`를 사용하고 slice를 사용하겠습니다. 이는 Tensor의 batch를 pre-computing하여 더 최적화 할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUVY0UM7ybu_",
        "colab_type": "code",
        "outputId": "bf57d12f-3551-4954-8f89-093bba44b0c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "input = line_to_tensor('Albert')\n",
        "hidden = torch.zeros(1, n_hidden)\n",
        "\n",
        "# 'Albert'의 'A'(t=1)만 전달.\n",
        "output, next_hidden = rnn(input[0], hidden)\n",
        "print(output)   # <1 x n_categories>"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-2.8203, -2.9312, -2.9243, -2.9394, -2.7699, -2.9901, -2.8974, -2.8139,\n",
            "         -2.8378, -2.9212, -2.9586, -2.8785, -2.8003, -2.8743, -2.8249, -2.9790,\n",
            "         -2.9449, -2.9594]], grad_fn=<LogSoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zliGXQXaykbz",
        "colab_type": "text"
      },
      "source": [
        "결과에서 볼 수 있듯, output은 `<1 x n_categories>` Tensor로, 모든 item은  category의 likelihood가 됩니다 (높을수록 확률이 높습니다)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYjeX0zezIBb",
        "colab_type": "text"
      },
      "source": [
        "# Training\n",
        "## 학습을 위한 준비과정\n",
        "학습을 시작하기 전에 도움이 될만한 함수를 만들겠습니다. 첫번째 함수는 네트워크의 output을 해석하는 함수로, 각 category의 likelihood입니다. `Tensor.topk`를 사용하여 가장 큰 값의 index를 구할 수 있습니다:\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk8gGP7_yfu6",
        "colab_type": "code",
        "outputId": "0f47ad21-08cd-43c6-9f3f-8ab3a8d2ae0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def category_from_output(output):\n",
        "    # torch.topk: return tok K values and indices\n",
        "    top_n, top_i = output.topk(1)\n",
        "    # torch.Tensor.item(): return value of this tensor\n",
        "    category_i = top_i[0].item()\n",
        "    return all_categories[category_i], category_i\n",
        "\n",
        "print(category_from_output(output))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Russian', 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIl3J6Qp1X33",
        "colab_type": "text"
      },
      "source": [
        "또한 training example을 얻는 빠른 방법을 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAUJ_ceM0x0S",
        "colab_type": "code",
        "outputId": "074ca0c3-adf7-4d0c-fc10-74670710160c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "import random\n",
        "\n",
        "def random_choice(l):\n",
        "    return l[random.randint(0, len(l) - 1)]\n",
        "\n",
        "def random_training_example():\n",
        "    # 랜덤하게 학습예제를 얻는 함수\n",
        "\n",
        "    # all_categories로부터 랜덤한 학습예제를 샘플링.\n",
        "    category = random_choice(all_categories)\n",
        "    # 위에서 선택한 category(i.e. language)로부터 학습할 이름을 샘플링.\n",
        "    line = random_choice(category_lines[category])\n",
        "    # category index를 tensor 형태로 변환함.\n",
        "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
        "    line_tensor = line_to_tensor(line)  # <line_length x 1 x n_letters> == <5 x 1 x 57>\n",
        "    return category, line, category_tensor, line_tensor\n",
        "\n",
        "for i in range(10):\n",
        "    category, line, category_tensor, line_tensor = random_training_example()\n",
        "    print(f\"category = {category},/ line = {line}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "category = Portuguese,/ line = Alves\n",
            "category = English,/ line = Little\n",
            "category = Chinese,/ line = Fan\n",
            "category = Arabic,/ line = Hajjar\n",
            "category = Irish,/ line = Macdermott\n",
            "category = Chinese,/ line = Geng\n",
            "category = French,/ line = Romilly\n",
            "category = Arabic,/ line = Bitar\n",
            "category = Portuguese,/ line = D'cruze\n",
            "category = Portuguese,/ line = Ferro\n",
            "torch.Size([5, 1, 57])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H38IUgx-21ga",
        "colab_type": "text"
      },
      "source": [
        "## Network 학습\n",
        "\n",
        "loss function의 경우 마지막 레이어에서 `nn.LogSoftmax`를 사용했기 때문에 `nn.NLLLoss`가 적절합니다.\n",
        "\n",
        ">  Obtaining log-probabilities in a neural network is easily achieved by adding a LogSoftmax layer in the last layer of your network. You may use CrossEntropyLoss instead, if you prefer not to add an extra layer.  \n",
        "- Input: (N, C)  \n",
        "- Target: (N)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiGl9e7V2m-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfFRze2l3vZ_",
        "colab_type": "text"
      },
      "source": [
        "training 과정에서의 매 loop에서 할 일은:\n",
        "- input과 target tensors를 만든다.\n",
        "- 0으로 초기화된 initial hidden state를 만든다.\n",
        "- 각 글자를 읽어들인다.\n",
        " - 다음 글자를 위해 hidden state를 저장한다.\n",
        "- 마지막 output과 target을 비교한다.\n",
        "- Back-propagation을 수행한다.\n",
        "- Output과 loss를 반환한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SY1oJO9F4ZeJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.005   # 너무 클 경우 explode하고, 작을 경우 학습이 되지 않습니다.\n",
        "\n",
        "# 원본에선 Optimizer를 사용하는 대신 직접 gradient를 계산합니다.\n",
        "optimizer = torch.optim.SGD(rnn.parameters(), lr=learning_rate)\n",
        "\n",
        "def train(category_tensor, line_tensor):\n",
        "    # 0으로 초기화된 initial hidden state를 만든다.\n",
        "    hidden = rnn.init_hidden()\n",
        "\n",
        "    rnn.zero_grad()\n",
        "\n",
        "    # 각 글자를 읽어들인다.\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        # 다음 글자를 위해 hidden state를 저장한다.\n",
        "        output, hidden = rnn(line_tensor[i], hidden)\n",
        "    # 마지막 output과 target을 비교한다.\n",
        "    loss = criterion(output, category_tensor)\n",
        "    # Back-propagation을 수행한다.\n",
        "    # Graident가 쌓여야 하므로 RNN이 다 돌았을 때 back-prop을 해줍니다.\n",
        "    loss.backward()\n",
        "    '''\n",
        "    # 원본은 step을 사용하는 대신 아래와 같은 방법으로 시도합니다.\n",
        "\n",
        "    # Add parameters' gradients to their values, multiplied by learning rate\n",
        "    for p in rnn.parameters():\n",
        "        p.data.add_(-learning_rate, p.grad.data)\n",
        "    '''\n",
        "    optimizer.step()\n",
        "    # output과 loss를 반환한다.\n",
        "    return output, loss.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agw3HDlaD3CJ",
        "colab_type": "text"
      },
      "source": [
        "이제 한 뭉치의 예제 (a bunch of example)을 통해 실행시키면 됩니다. `train` 함수는 output과 loss를 반환하기 때문에, 예측값과 loss값을 plotting할 수 있습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjr36n6H5r7q",
        "colab_type": "code",
        "outputId": "1be3e61d-4d06-418a-dc6a-1be1e4eae94a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "n_iters = 100000\n",
        "# 일부분만 출력/plotting\n",
        "print_every = 5000\n",
        "plot_every = 1000\n",
        "\n",
        "# loss값을 기록하기\n",
        "current_loss = 0\n",
        "all_losses = []\n",
        "\n",
        "def time_since(since):\n",
        "    # 시작점(since)과 현재 시간의 차이를 반환하는 함수\n",
        "\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return f\"{m}m {s}s\"\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "for iter in range(1, n_iters + 1):\n",
        "    # input과 target tensors를 만든다.\n",
        "    category, line, category_tensor, line_tensor = random_training_example()\n",
        "    output, loss = train(category_tensor, line_tensor)\n",
        "    current_loss += loss\n",
        "\n",
        "    # print iter number, loss, name and guess\n",
        "    if iter % print_every == 0:\n",
        "        # 이전에 정의한 output interpreter를 이용하여 예측값 출력\n",
        "        guess, guess_i = category_from_output(output)\n",
        "        correct = '✓' if guess == category else f'✗ {category}'\n",
        "        # iter, 진행률, 걸린시간, loss, 이름, prediction, 정답\n",
        "        print(f\"{iter} {iter/n_iters * 100}% ({time_since(start)}) {loss} {line} {guess} {correct}\")\n",
        "\n",
        "    # 현재 avg loss list of losses에 저장함\n",
        "    if iter % plot_every == 0:\n",
        "        all_losses.append(current_loss/ plot_every)\n",
        "        current_loss = 0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000 5.0% (0m 5.769678831100464s) 2.3346517086029053 Jarsky Russian ✓\n",
            "10000 10.0% (0m 11.287590980529785s) 2.492717981338501 Almeida Czech ✗ Portuguese\n",
            "15000 15.0% (0m 17.23438858985901s) 1.296158790588379 Zhui Chinese ✓\n",
            "20000 20.0% (0m 23.064869165420532s) 2.29429292678833 Holub Arabic ✗ Czech\n",
            "25000 25.0% (0m 28.62803602218628s) 0.5351735353469849 Nelli Italian ✓\n",
            "30000 30.0% (0m 35.078956842422485s) 1.328761339187622 Borovsky Russian ✗ Czech\n",
            "35000 35.0% (0m 41.236451148986816s) 1.7228971719741821 Bazzi Italian ✗ Arabic\n",
            "40000 40.0% (0m 47.063740491867065s) 1.3786357641220093 Araullo Italian ✗ Spanish\n",
            "45000 45.0% (0m 53.35244631767273s) 0.5496755838394165 Qing Chinese ✓\n",
            "50000 50.0% (0m 59.5142924785614s) 2.987123489379883 Baz Chinese ✗ Arabic\n",
            "55000 55.00000000000001% (1m 5.926255464553833s) 0.05695939436554909 Strilakos Greek ✓\n",
            "60000 60.0% (1m 11.774405241012573s) 1.0855873823165894 Maradona Spanish ✓\n",
            "65000 65.0% (1m 17.6542227268219s) 0.2468671351671219 Dinh Vietnamese ✓\n",
            "70000 70.0% (1m 23.985372304916382s) 1.5442312955856323 Antwerp English ✗ Dutch\n",
            "75000 75.0% (1m 29.47744870185852s) 0.2056233137845993 Crawford Scottish ✓\n",
            "80000 80.0% (1m 35.58166861534119s) 0.24123050272464752 Chweh Korean ✓\n",
            "85000 85.0% (1m 41.783530712127686s) 1.074991226196289 Tomasek Polish ✗ Czech\n",
            "90000 90.0% (1m 48.41811656951904s) 2.806579113006592 Nifterick Polish ✗ Dutch\n",
            "95000 95.0% (1m 54.16662859916687s) 3.8978044986724854 Mathieu Vietnamese ✗ French\n",
            "100000 100.0% (2m 0.1560354232788086s) 1.583416223526001 Polites Dutch ✗ Greek\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLHSBa4qWP40",
        "colab_type": "text"
      },
      "source": [
        "# Plotting the Result\n",
        "\n",
        "`all_losses`에 저장된 loss값들을 그려보면 network의 학습하는 과정을 볼 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkvYINtsQNW1",
        "colab_type": "code",
        "outputId": "e5fb2145-b8ec-40ee-d473-529386efde64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(all_losses)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fed12e21d68>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDXqllHJyGvRKKeXkNOiVUsrJ/X/iWQGujjNX5QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM3x1uIchBlk",
        "colab_type": "text"
      },
      "source": [
        "# 결과 평가하기\n",
        "다른 카테고리에서 네트워크가 얼마나 잘 작동하는지 보기 위해 confusion matrix를 만들겠습니다. Confusion matrix는 모든 정답 언어(row)와 네트워크의 예측(column)을 보여줍니다. Confusion matrix를 만들기 위해서는 sample 뭉치를 `evaluate()`를 통하여 네트워크를 실행시키면 됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoHY1uX8cfau",
        "colab_type": "code",
        "outputId": "367b3c71-47ee-4151-f3ef-6f354c28713e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "# Confusion matrix에서 정답의 개수를 기록\n",
        "confusion = torch.zeros(n_categories, n_categories)\n",
        "n_confusion = 10000\n",
        "\n",
        "# line에 대해 output을 return함.\n",
        "def evaluate(line_tensor):\n",
        "    hidden = rnn.init_hidden()\n",
        "\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        output, hidden = rnn(line_tensor[i], hidden)\n",
        "\n",
        "    return output\n",
        "\n",
        "# 예제를 넣고 얼마나 맞는지 확인함.\n",
        "for i in range(n_confusion):\n",
        "    category, line, category_tensor, line_tensor = random_training_example()\n",
        "    output = evaluate(line_tensor)\n",
        "    guess, guess_i = category_from_output(output)\n",
        "    category_i = all_categories.index(category)\n",
        "    confusion[category_i][guess_i] += 1\n",
        "\n",
        "# row의 합으로 나누어 normalize\n",
        "for i in range(n_categories):\n",
        "    confusion[i] = confusion[i] / confusion[i].sum()\n",
        "\n",
        "# Plot 세팅\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(confusion.numpy())\n",
        "fig.colorbar(cax)\n",
        "\n",
        "# axes 세팅\n",
        "ax.set_xticklabels([''] + all_categories, rotation=90)\n",
        "ax.set_xticklabels([''] + all_categories)\n",
        "\n",
        "# Force label at every tick\n",
        "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "# sphinx_gallery_thumbnail_number = 2\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAS4AAAEwCAYAAAAJnJyoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRF4PtugAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwU4YLzZR1Lh",
        "colab_type": "text"
      },
      "source": [
        "# 사용자 데이터로 예측하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jf949O3fR0R7",
        "colab_type": "code",
        "outputId": "8ba056d6-3567-4e62-9432-4041982cd08d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "def predict(input_line, n_predictions=3):\n",
        "    print(f\"\\n> {input_line}\")\n",
        "    # prediction\n",
        "    with torch.no_grad():\n",
        "        output = evaluate(line_to_tensor(input_line))\n",
        "\n",
        "        # Top N category\n",
        "        topv, topi = output.topk(n_predictions, 1, True)\n",
        "\n",
        "        predictions = []\n",
        "\n",
        "        for i in range(n_predictions):\n",
        "            value = topv[0][i].item()\n",
        "            category_index = topi[0][i].item()\n",
        "            print(f'{value:.2f} {all_categories[category_index]}')\n",
        "            predictions.append([value, all_categories[category_index]])\n",
        "\n",
        "predict('Dovesky')\n",
        "predict('Jackson')\n",
        "predict('Satoshi')\n",
        "\n",
        "predict('Yoon')\n",
        "predict('Yoo')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "> Dovesky\n",
            "-0.52 Russian\n",
            "-1.29 Czech\n",
            "-2.61 Polish\n",
            "\n",
            "> Jackson\n",
            "-0.45 Scottish\n",
            "-2.07 English\n",
            "-2.58 Polish\n",
            "\n",
            "> Satoshi\n",
            "-1.05 Arabic\n",
            "-1.51 Japanese\n",
            "-1.67 Italian\n",
            "\n",
            "> Yoon\n",
            "-0.42 Korean\n",
            "-1.30 Chinese\n",
            "-4.11 English\n",
            "\n",
            "> Yoo\n",
            "-0.28 Korean\n",
            "-1.50 Chinese\n",
            "-5.21 Vietnamese\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzTqOfCo3efO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}