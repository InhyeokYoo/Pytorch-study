{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6.4.4.1 Char_RNN_Naive.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/InhyeokYoo/Pytorch-study/blob/master/6_4_4_1_Char_RNN_Naive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymgVATJ2aaqB",
        "colab_type": "text"
      },
      "source": [
        "# 데이터 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI5b2jhJaEa-",
        "colab_type": "code",
        "outputId": "cd8f9a30-6c1d-4389-fa8a-d7fd974a37b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!rm -r data\n",
        "import os \n",
        "\n",
        "try:\n",
        "  os.mkdir(\"./data\")\n",
        "except:\n",
        "  pass\n",
        "\n",
        "!wget https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt -P ./data"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-29 07:45:08--  https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘./data/input.txt’\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2019-11-29 07:45:09 (43.1 MB/s) - ‘./data/input.txt’ saved [1115394/1115394]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBivfBPnaOVv",
        "colab_type": "code",
        "outputId": "5e144b3d-7bf4-46e0-9aa5-c619c7661e5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4vllVHaadfV",
        "colab_type": "text"
      },
      "source": [
        "## 1) Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-S4M-dXaSoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2VgcJ_Eahot",
        "colab_type": "code",
        "outputId": "c6c7ed70-ee68-4a92-d487-da6a565a76b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install unidecode"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGbGeCqIajLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "import time, math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev2vHuHWYJ0R",
        "colab_type": "text"
      },
      "source": [
        "## 2) Hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX6YyP_qapQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 2000\n",
        "print_every = 100\n",
        "plot_every = 10\n",
        "\n",
        "chunk_len = 200\n",
        "\n",
        "hidden_size = 100\n",
        "batch_size = 1\n",
        "num_layers = 1\n",
        "embedding_size = 70\n",
        "lr = 0.002"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvUWgNqVYaYO",
        "colab_type": "text"
      },
      "source": [
        "# 2. Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbyn0yp9Yn6_",
        "colab_type": "text"
      },
      "source": [
        "## 1) Prepare characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezg8fTuHYY8X",
        "colab_type": "code",
        "outputId": "ed6f5d9a-ad62-436b-de33-cd0fb46b5a65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# string module에서 출력 가능한 문자를 모두 불러오자.\n",
        "all_characters = string.printable\n",
        "print(all_characters)\n",
        "\n",
        "# 출력가능한 문자들의 개수를 저장해놓는다.\n",
        "n_characters = len(all_characters)\n",
        "print(n_characters)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
            "\r\u000b\f\n",
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnHcn1OqZFTs",
        "colab_type": "text"
      },
      "source": [
        "## 2) Get Text Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PrYRuxkY42R",
        "colab_type": "code",
        "outputId": "caa8f2fb-6727-4f7d-a590-55629a14818f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 앞서 다운받은 텍스트 파일을 열어준다.\n",
        "file = unidecode.unidecode(open('./data/input.txt').read())\n",
        "file_len = len(file)\n",
        "print('file_len', file_len)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file_len 1115394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8kHEQsTZcqT",
        "colab_type": "text"
      },
      "source": [
        "# 3. functions for text processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ON5wedJraGUF",
        "colab_type": "text"
      },
      "source": [
        "## 1) Random chunk\n",
        "Q. 왜 필요한건지 이해가 되지 않음."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0ZGyNWTZWbO",
        "colab_type": "code",
        "outputId": "c778fc9c-1f92-4dc4-bca7-fa2efce0da59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# 텍스트 파일의 일부를 불러오는 함수\n",
        "def random_chunk():\n",
        "    # (시작지점 < 텍스트 전체 길이 - 불러오는 길이)\n",
        "    start_index = random.randint(0, file_len - chunk_len)\n",
        "    end_index = start_index + chunk_len + 1\n",
        "    return file[start_index:end_index]\n",
        "\n",
        "print(random_chunk())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "in some vantage.\n",
            "But make you ready your stiff bats and clubs:\n",
            "Rome and her rats are at the point of battle;\n",
            "The one side must have bale.\n",
            "Hail, noble Marcius!\n",
            "\n",
            "MARCIUS:\n",
            "Thanks. What's the matter, you d\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEej46x9aDIv",
        "colab_type": "text"
      },
      "source": [
        "## 2). char to tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FIAWoX9Z7JZ",
        "colab_type": "code",
        "outputId": "ab9583a0-04f6-4283-d3ef-dcc9c69ec3f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 문자열을 받았을 때, 이를 indices로 바꾸어서 return함.\n",
        "def char_tensor(string):\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        tensor[c] = all_characters.index(string[c])\n",
        "    return tensor\n",
        "\n",
        "print(char_tensor('ABCdef'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([36, 37, 38, 13, 14, 15])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y3rgrvsa2qj",
        "colab_type": "text"
      },
      "source": [
        "## 3) chunk into input & label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d76TgO-ta0tp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 인덱스화된 문자열을 입력값과 목표값으로 나눠주는 함수\n",
        "# pytorch: pytorc -> ytorch\n",
        "\n",
        "def random_training_set():\n",
        "    chunk = random_chunk() # random하게 잘린 문자열\n",
        "    input_ = char_tensor(chunk[:-1])\n",
        "    target = char_tensor(chunk[1:])\n",
        "    return input_, target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQrRbcH8bgZW",
        "colab_type": "text"
      },
      "source": [
        "# 3. Model & Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq6mySXxbfN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size # 실제 input의 사이즈가 아니라, embedding lookup table의 개수.\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Embedding\n",
        "        self.encoder = nn.Embedding(self.input_size, self.embedding_size)\n",
        "        self.rnn = nn.RNN(self.embedding_size, self.hidden_size, self.num_layers)\n",
        "        self.decoder = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input_, hidden):\n",
        "        output = input_.view(1, -1) # [1 x 1]\n",
        "        \n",
        "        # embedding에선 indices들을 전달한다\n",
        "        # e.g. torch.LongTensor([[1,2,4,5],[4,3,2,9]]) -> 2개의 batch, [1, 2, 4, 5] 번째 indices와 [4, 3, 2, 9]의 indices\n",
        "        output = self.encoder(output) # [bacth x 1 x embedding_size]\n",
        "        # print('after emgedding', output.size())\n",
        "        \n",
        "        # hidden: [num_layers * num_directions, batch, hidden_size]\n",
        "        # output: [seq_len, batch, num_directions * hidden_size]\n",
        "        output, hidden = self.rnn(output, hidden)\n",
        "        # print('before view output:', output.size())\n",
        "        # print('after decoder output:', output.view(batch_size, -1).size())\n",
        "        output = self.decoder(output.view(batch_size, -1))\n",
        "        return output, hidden\n",
        "    \n",
        "    def init_hidden(self):\n",
        "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "        return hidden\n",
        "\n",
        "model = RNN(n_characters, embedding_size, hidden_size, n_characters, num_layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eixhONFH3str",
        "colab_type": "text"
      },
      "source": [
        "```torch.nn.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False, _weight=None)```  \n",
        "A simple lookup table that stores embeddings of a fixed dictionary and size.\n",
        "\n",
        "This module is often used to store word embeddings and retrieve them using indices. The input to the module is a list of indices, and the output is the corresponding word embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThZVyHZXRnuv",
        "colab_type": "code",
        "outputId": "7ed38824-49a4-4296-afc7-a456b32b6fb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Embedding 연습\n",
        "\n",
        "embedding = nn.Embedding(10, 3)\n",
        "\n",
        "# a batch of 2 samples of 4 indices each\n",
        "indices = torch.LongTensor([[1,2,4,5],[4,3,2,9]]) # 2 x 4\n",
        "\n",
        "embedding(indices) # [2 x 4 x 3] -> [(batch_size, indices), embedding_dim]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2434, 0.0799, 0.0629]], grad_fn=<EmbeddingBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj-2IzVuKzqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = RNN(input_size=n_characters, \n",
        "            embedding_size=embedding_size,\n",
        "            hidden_size=hidden_size, \n",
        "            output_size=n_characters, \n",
        "            num_layers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGuJ8QXzidzj",
        "colab_type": "code",
        "outputId": "77f36fd0-1429-495d-938b-5032b084b8d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# 모델 테스트\n",
        "\n",
        "inp = char_tensor(\"A\")\n",
        "print(inp, inp.size())\n",
        "print('View 적용:', inp.view(1, -1), inp.view(1, -1).size())\n",
        "\n",
        "embedding = nn.Embedding(100, 100)\n",
        "word_vector = embedding(inp.view(1, -1))\n",
        "print('after embedding', word_vector.size())\n",
        "\n",
        "hidden = model.init_hidden()\n",
        "print(hidden.size())\n",
        "out, hidden = model(inp, hidden)\n",
        "print(out.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([36]) torch.Size([1])\n",
            "View 적용: tensor([[36]]) torch.Size([1, 1])\n",
            "after embedding torch.Size([1, 1, 100])\n",
            "torch.Size([2, 1, 100])\n",
            "before view output: torch.Size([1, 1, 100])\n",
            "after decoder output: torch.Size([1, 100])\n",
            "torch.Size([1, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9peY88Xkkyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_func = nn.CrossEntropyLoss() # 여긴 시발 또 cross entropy네?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRS7T-5yk75t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test function\n",
        "# 임의의 문자 start_str 로 시작하는 길이 200짜리 모방 글을 생성하는 예제\n",
        "\n",
        "def test():\n",
        "    start_str = 'b'\n",
        "    inp = char_tensor(start_str)\n",
        "    hidden = model.init_hidden()\n",
        "    x = inp\n",
        "\n",
        "    print(start_str, end='')\n",
        "\n",
        "    for i in range(200):\n",
        "        output, hidden = model(x, hidden)\n",
        "\n",
        "        # 여기서는 max값을 쓰지 않고 multinomial을 사용하는 이유는 만약 max값만 쓰는 경우에\n",
        "        # 생성되는 text가 the the the ... 만 나오기 때문임.\n",
        "        # multinomial 함수를 통해 높은 값을 가지는 문자들에 대해서 랜덤하게 다음 글자를 뽑아내는 방식으로 텍스트를 생성해보자\n",
        "\n",
        "        output_dist = output.data.view(-1).div(0.8).exp() # Q. 굳이 이렇게 한 이유는?\n",
        "\n",
        "        # input은 sample이고, 얼마나 뽑을지 결정하면 됨.\n",
        "        top_i = torch.multinomial(output_dist, 1)[0] # [0]은 scalar값만 가져오겠단 소리.\n",
        "        predicted_char = all_characters[top_i]\n",
        "\n",
        "        print(predicted_char, end=\"\")\n",
        "\n",
        "        x = char_tensor(predicted_char)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Psydzwzh-g9o",
        "colab_type": "code",
        "outputId": "41c05d58-96f4-436a-e254-bbb8da6f29cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train\n",
        "# model = RNN(n_characters, embedding_size, hidden_size, n_characters, num_layers)\n",
        "\n",
        "for i in range(num_epochs):\n",
        "    # 랜덤한 텍스트 덩어리를 sampling하고, 이를 index tensor로 변환한다.\n",
        "    input_, label = random_training_set() # 200개 짜리 chunk된 word의 indices\n",
        "    hidden = model.init_hidden()\n",
        "    \n",
        "    # Q. 왜 굳이 tensor로 loss를 받는가?\n",
        "    loss = torch.tensor([0]).type(torch.FloatTensor) # loss = 0 이라도 잘 작동함.\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for j in range(chunk_len - 1):\n",
        "        x = input_[j] # 글자 하나의 index -> tensor(22)\n",
        "\n",
        "        # torch.unsqueeze(input, dim) -> 특정 자리에 차원을 추가하는 함수.\n",
        "        y_ = label[j].unsqueeze(0).type(torch.LongTensor) # -> tensor([22]), 1x1\n",
        "        y, hidden = model(x, hidden)\n",
        "        loss += loss_func(y, y_)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 100 ==0:\n",
        "        print(\"\\n\",loss/chunk_len,\"\\n\")\n",
        "        test()\n",
        "        print(\"\\n\",\"=\"*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " tensor(4.5962, grad_fn=<DivBackward0>) \n",
            "\n",
            "bkfwXle%Nh>#45L,]kX/ZN (Oz}4HLt^esHOZ\u000b?N#ORPlr@?n=GLAn=vt/#l8nED-j_97Q\"AZZH@U<1P|gSw$KU1:i@yY]'8c4q|cji/H<%'@Jd\":}5cEdIf+.TKfgD~[).7;d|^o\\YL~[WYQNvYr3Dw~\"\t]r\u000b\n",
            ">)7l<UTJN[Cy:OqLDx4uf}cc0tG9/qd\"!X9-1;f\u000b%}\n",
            " ====================================================================================================\n",
            "\n",
            " tensor(2.3547, grad_fn=<DivBackward0>) \n",
            "\n",
            "bJ\n",
            "Tovin\n",
            "War sou sor, there aste pafes, abt uond,;\n",
            "\n",
            "O min mawis tarino to the whes fo ga; wot. tareey wiag the the thoud Wd lL roul thor whis,\n",
            "That yith th shers fallin roy eins ,ow thes wile seor ther\n",
            " ====================================================================================================\n",
            "\n",
            " tensor(2.2918, grad_fn=<DivBackward0>) \n",
            "\n",
            "bure an me withee zece norfes and thet in of' tire Hot tim lo wing Mell sis will thel\n",
            "\n",
            "CD'''s mell not they ourt; beeat yite! mris maew\n",
            "\n",
            "Sowat yarincere fou raos thov, lich ther st.\n",
            "LE:\n",
            "Act nof I EH:\n",
            "T\n",
            " ====================================================================================================\n",
            "\n",
            " tensor(2.2984, grad_fn=<DivBackward0>) \n",
            "\n",
            "been the aus, the cance of, sungust blise bulla gheon the mase the shas waly suy and\n",
            "Thenere,\n",
            "I shame jour noce be fom hand thear hak semall I thou hill ongy way thour whaan shell\n",
            "Hirs aw and for hake,\n",
            " ====================================================================================================\n",
            "\n",
            " tensor(2.0571, grad_fn=<DivBackward0>) \n",
            "\n",
            "benther thour thy go; rectill nowerd sicing, to I this mall is your deser and yanted your marterse, the be of hith hall the of wackon raterow to me lreatnes in and\n",
            "My Of how you En thenerenuo,\n",
            "As me my\n",
            " ====================================================================================================\n",
            "\n",
            " tensor(2.1530, grad_fn=<DivBackward0>) \n",
            "\n",
            "beed, the bir\n",
            "He beime panlished orshince bew in of ishe for theal the witen: sick lipe ce our lobrede of me he blich yaur nother thy the here Hechercand byat and bot upan\n",
            "to beef of sonet, notre is hi\n",
            " ====================================================================================================\n",
            "\n",
            " tensor(2.2009, grad_fn=<DivBackward0>) \n",
            "\n",
            "bear'd hercand;\n",
            "Whis that ate,\n",
            "Whoth hange, not ster sout atem's wiqgoid there, this briin:\n",
            "And but brist love to were me mirone fill is good the to mace spaccarn, the wace is for ros mest to rime upor\n",
            " ====================================================================================================\n",
            "\n",
            " tensor(2.0555, grad_fn=<DivBackward0>) \n",
            "\n",
            "but me thiu the way us.\n",
            "A'd a peath bettert lake wise whome, whot thou his lecerqunthan deall you then the chim with then in be sirexs mave the noth me malt that have hourel by prove whon fach,\n",
            "That an\n",
            " ====================================================================================================\n",
            "\n",
            " tensor(1.8761, grad_fn=<DivBackward0>) \n",
            "\n",
            "bles: and not marlounlo;\n",
            "What to mave with rising,\n",
            "Wates, hath the marry my now chall math nalady my dage saing our cave, no digh, I bees our his not my moreds swankon, wartor,\n",
            "To your more stheres?\n",
            "\n",
            "Y\n",
            " ====================================================================================================\n",
            "\n",
            " tensor(1.7241, grad_fn=<DivBackward0>) \n",
            "\n",
            "buch seing of the sing thee, as the raye's is manite the rave, in a be in with is and the be come and of mimes\n",
            "To and thinat, whill not be me he mast.\n",
            "\n",
            "AUTIO:\n",
            "Low ne dear, all Romsee,\n",
            "I conour gike,\n",
            "Yo\n",
            " ====================================================================================================\n",
            "\n",
            " tensor(2.2297, grad_fn=<DivBackward0>) \n",
            "\n",
            "by a what the of my rod denence in the pightend,\n",
            "The I and stood me is thy fatherforder?\n",
            "\n",
            "GaMere fime, her of then dellany:\n",
            "I dadus self theigattune what his furdow of sumest in son't\n",
            "manterserth not h\n",
            " ====================================================================================================\n",
            "\n",
            " tensor(2.0889, grad_fn=<DivBackward0>) \n",
            "\n",
            "bart nin.\n",
            "Whif, for the sury be our for mones, and with me, here\n",
            "The mare hear their reating mosher ridest hall teety more beed'd hence with dow kear the for no ale they\n",
            "by the to cerfige; and in't\n",
            "Sel\n",
            " ====================================================================================================\n",
            "\n",
            " tensor(2.0619, grad_fn=<DivBackward0>) \n",
            "\n",
            "ble te no call your and a belliin\n",
            "your fanks.\n",
            "\n",
            "PLOUCENTAO:\n",
            "A alaged here ondear of this pore word and their no. What!\n",
            "\n",
            "GLUCELIO:\n",
            "And not thing her,\n",
            "But a woughture of at I'll you,\n",
            "The aldry\n",
            "us the blan\n",
            " ====================================================================================================\n",
            "\n",
            " tensor(1.7669, grad_fn=<DivBackward0>) \n",
            "\n",
            "by if a gited and my must,\n",
            "And thou be with me and come, blentle that you hood be ofard the cention have send the prishis with you wank prich cate your be with to lince to lend'd, that well in thew coo\n",
            " ====================================================================================================\n",
            "\n",
            " tensor(1.5895, grad_fn=<DivBackward0>) \n",
            "\n",
            "bren, and tell to hesper'd pack love lavant:\n",
            "Herefime,\n",
            "And Ongore couls\n",
            "and ow and she ore have have whis,\n",
            "And my plant's\n",
            "To knot sperder, be eecile ever her of have have is beitner,\n",
            "A prisifer\n",
            "To gire\n",
            " ====================================================================================================\n",
            "\n",
            " tensor(1.9095, grad_fn=<DivBackward0>) \n",
            "\n",
            "bliad to my lovates!\n",
            "\n",
            "QUCIINIO:\n",
            "My thil, enour stand that,\n",
            "To not same live sain this my more arciest\n",
            "Marron thee know in the ride to Rinelenter are to my make coull ny abless;\n",
            "What partly him, to shal\n",
            " ====================================================================================================\n",
            "\n",
            " tensor(1.9035, grad_fn=<DivBackward0>) \n",
            "\n",
            "by for mand that noted.\n",
            "\n",
            "ThARD:\n",
            "For horrow en,\n",
            "For his this no Bucko.\n",
            "\n",
            "SSPERAT:\n",
            "He you,\n",
            "To my for thy for the see lord,\n",
            "All faster and from then you mandy I song them Vound warge, harstignatime,\n",
            "So thi\n",
            " ====================================================================================================\n",
            "\n",
            " tensor(1.6205, grad_fn=<DivBackward0>) \n",
            "\n",
            "bet,\n",
            "That the seny more to to for her stence thou arsaman be more, wow I and he bolly with have nost that for henger a bore bide pofor:\n",
            "Po ext for deaton a bight, we dears I hear a will teten, and, a n\n",
            " ====================================================================================================\n",
            "\n",
            " tensor(1.7374, grad_fn=<DivBackward0>) \n",
            "\n",
            "bet sir, counted his not, good, And mean of my ploods you which you heap this mear come hindess tell the cens her his gate hold heen our lading hor thou fhace, like weart\n",
            "indedse! thy loup onour will f\n",
            " ====================================================================================================\n",
            "\n",
            " tensor(1.6873, grad_fn=<DivBackward0>) \n",
            "\n",
            "by to to thy grope, will by whin by lears:\n",
            "\n",
            "Byop thea meres is to chad the wright the crove ut in the better a trracker how him.\n",
            "\n",
            "ROMEO:\n",
            "It uper, in her I will supbay the made thy kish the watis hank t\n",
            " ====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2HvJsrWmQDX",
        "colab_type": "text"
      },
      "source": [
        "# Experiment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfmHywoLmSu9",
        "colab_type": "text"
      },
      "source": [
        "## batch_size가 여러개인 RNN 모델을 직접 짜보자.\n",
        "\n",
        "사실 모델 내에서 batch 부분에 대해서 건들 것이 없음. 기존의 [input] -> [output] 구조를, [batch x input] -> [batch x output] 으로 바꿔주면 됨."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zt4L66s1mdSu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Hyper parameters\n",
        "num_epochs = 2000\n",
        "print_every = 100\n",
        "plot_every = 10\n",
        "chunk_len = 200\n",
        "hidden_size = 100\n",
        "batch_size = 5\n",
        "num_layers = 2\n",
        "embedding_size = 70\n",
        "lr = 0.002"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMaH2vxbmOgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNNBatch(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # Architecture\n",
        "        self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n",
        "        self.rnn = nn.RNN(self.embedding_size, self.hidden_size, self.num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input_, hidden):\n",
        "        # input: [batch] == [5]\n",
        "\n",
        "        # Embedding\n",
        "        # input: [batch x indices] == [5 x 1] 우리는 단어마다 받을 것 (seq_len=1)\n",
        "        output = self.embedding(input_.view(batch_size, -1))\n",
        "        # output: [batch x indices x dim] == [5 x 1 x 100]\n",
        "\n",
        "        # RNN\n",
        "        # input: [batch, seq_len, features] == [5 x 1 x 100]. seq_len=1 이고 embedding_size가 input dim\n",
        "        # hidden: [num_layers * num_directions, batch, hidden_Size] == [2, 5, 100]\n",
        "        output, hidden = self.rnn(output, hidden)\n",
        "        # output: [batch, seq_len, features] == [5, 1, 100]. input과 같음.\n",
        "        # hidden: [num_layers * num_directions, batch, hidden_size] == [2, 5, 100]\n",
        "\n",
        "        # FC\n",
        "        # input: [batch_size, in_features] = [5 x 100]\n",
        "        output = output.view(batch_size, -1) # [2, 5, 100] -> [5, 100]\n",
        "        output = self.fc(output)\n",
        "        # output: [batch_size, output_size]\n",
        "        output = nn.functional.log_softmax(output)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        hidden = torch.zeros(self.num_layers * 1, batch_size, self.hidden_size)\n",
        "        return hidden\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOTiFaYZv-p9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = RNNBatch(input_size=n_characters,\n",
        "          embedding_size=embedding_size,\n",
        "          hidden_size=hidden_size,\n",
        "          output_size=n_characters,\n",
        "          num_layers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x3lldA9t-6NG",
        "colab": {}
      },
      "source": [
        "# test function\n",
        "# 임의의 문자 start_str 로 시작하는 길이 200짜리 모방 글을 생성하는 예제\n",
        "\n",
        "def test_with_batch():\n",
        "    start_str = 'bbbbb'\n",
        "    inp = char_tensor(start_str) # [x, x, x, .. , x]\n",
        "    hidden = model.init_hidden()\n",
        "    x = inp\n",
        "    predicted_chars = ['' for _ in range(batch_size)]\n",
        "    print(start_str, end='')\n",
        "\n",
        "    for i in range(200):\n",
        "        output, hidden = model(x, hidden)\n",
        "\n",
        "        # 여기서는 max값을 쓰지 않고 multinomial을 사용하는 이유는 만약 max값만 쓰는 경우에\n",
        "        # 생성되는 text가 the the the ... 만 나오기 때문임.\n",
        "        # multinomial 함수를 통해 높은 값을 가지는 문자들에 대해서 랜덤하게 다음 글자를 뽑아내는 방식으로 텍스트를 생성해보자\n",
        "\n",
        "        output_dist = output.data.div(0.8).exp() \n",
        "        top_i = torch.multinomial(output_dist, 1).view(-1)\n",
        "        predicted_char = [all_characters[item] for item in top_i]\n",
        "        predicted_chars = [predicted_chars[item] + predicted_char[item] for item in range(batch_size)]\n",
        "\n",
        "\n",
        "        x = char_tensor(\"\".join(predicted_char))\n",
        "    \n",
        "    for item in predicted_chars:\n",
        "        print(item, sep='\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34awPGucwjQN",
        "colab_type": "code",
        "outputId": "45a30bae-efe8-456a-d888-b1083fa19a49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        }
      },
      "source": [
        "# 모델 테스트\n",
        "\n",
        "inp = char_tensor(\"ABCDE\")\n",
        "print(inp, inp.size())\n",
        "print('View 적용:', inp.view(1, -1), inp.view(batch_size, -1).size())\n",
        "\n",
        "embedding = nn.Embedding(100, 70)\n",
        "word_vector = embedding(inp.view(batch_size, -1))\n",
        "print('after embedding', word_vector.size())\n",
        "\n",
        "hidden = model.init_hidden()\n",
        "print(hidden.size())\n",
        "out, hidden = model(inp, hidden)\n",
        "print(out.size())\n",
        "\n",
        "# test 함수\n",
        "# output_dist = out.data.view(-1).div(0.8).exp()\n",
        "output_dist = out.data.div(0.8).exp()  # batch의 경우, view를 안해줘야 되니까.\n",
        "print(output_dist.size())\n",
        "\n",
        "print('='*100)\n",
        "print('multinomial')\n",
        "top_i = torch.multinomial(output_dist, 1)\n",
        "print(top_i, top_i.size())\n",
        "top_i = top_i.view(-1)\n",
        "print(top_i)\n",
        "predicted_char = [all_characters[item] for item in top_i]\n",
        "print(predicted_char)\n",
        "predicted_chars = ['' for _ in range(batch_size)]\n",
        "predicted_chars = [predicted_chars[item] + predicted_char[item] for item in range(batch_size)]\n",
        "print(predicted_chars)\n",
        "x = char_tensor(\"\".join(predicted_char))\n",
        "print(x)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([36, 37, 38, 39, 40]) torch.Size([5])\n",
            "View 적용: tensor([[36, 37, 38, 39, 40]]) torch.Size([5, 1])\n",
            "after embedding torch.Size([5, 1, 70])\n",
            "torch.Size([2, 5, 100])\n",
            "torch.Size([5, 100])\n",
            "torch.Size([5, 100])\n",
            "====================================================================================================\n",
            "multinomial\n",
            "tensor([[31],\n",
            "        [69],\n",
            "        [51],\n",
            "        [ 3],\n",
            "        [62]]) torch.Size([5, 1])\n",
            "tensor([31, 69, 51,  3, 62])\n",
            "['v', '(', 'P', '3', '!']\n",
            "['v', '(', 'P', '3', '!']\n",
            "tensor([31, 69, 51,  3, 62])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNbsE-lSxB2I",
        "colab_type": "text"
      },
      "source": [
        "잘 나오는 것을 확인함. 그러나 문제는 training하는 과정인데..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG-JKQsKxDFo",
        "colab_type": "code",
        "outputId": "42756b91-6f78-421a-8776-1783e2e93bfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_func = nn.NLLLoss() # multinomial이라서 Cross Entropy 사용 X\n",
        "\n",
        "for i in range(num_epochs):\n",
        "    # 랜덤한 텍스트 덩어리를 sampling하고, 이를 index tensor로 변환한다.\n",
        "    input_, label = random_training_set() # chunk_len = 200 이므로, 5의 배수.\n",
        "    hidden = model.init_hidden()\n",
        "    # print(input_.size())\n",
        "    \n",
        "    loss = torch.tensor([0]).type(torch.FloatTensor)\n",
        "    optimizer.zero_grad()\n",
        "    for j in range(chunk_len - batch_size): # chunck_len - 1 - (batch_size) + 1\n",
        "        x = torch.stack([input_[j+k:j+k+1] for k in range(batch_size)], dim=0) # [5, 1]\n",
        "        y_ = torch.stack([label[j+k+1:j+k+1+1] for k in range(batch_size)],dim=0) # [5, 1]\n",
        "        y_ = y_.view(-1).long() # [batch_size, 1]\n",
        "        y, hidden = model(x, hidden) # [batch_size, output_size]\n",
        "        # print(y.size(), y_.size())\n",
        "        loss += loss_func(y, y_)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 100 ==0:\n",
        "        print(\"\\n\",loss/chunk_len,\"\\n\")\n",
        "        # test를 해야 하는데, batch size가 다를 경우에는 어떻게 inference를 진행하지...?\n",
        "        test_with_batch()\n",
        "        print(\"\\n\",\"=\"*100)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " tensor([4.4976], grad_fn=<DivBackward0>) \n",
            "\n",
            "bbbbb354OT\tM0TcpyS%abN1,lJ='\t[I?<Vo.}{#[i\rtEl~&*4rxg]).!Ct=*_2T4Y}n!kP3\t'_f:\n",
            "\u000bE&~dk.#1rEr3?$B1{7Z~,+J4! biZga\u000bSTUXiS_Kn-0|sd\n",
            "n75>4wHejnf>{?{\f2}aQgNQ|U'/V5|vZak@o?B5<_P~R_^ ,]v#Rr%s$}gG{9LZwQg ;@e-\"/4K1CkZE\n",
            "N96\n",
            "3Xv+*`VGUlP@,ay%#V!\"5W\u000b7d x~8~qs36\u000baY\n",
            "LmIwY['|\\?D]t(8*Ty-lggQ\fX\"\fte'rSH\rU*]:ES\fCO\u000b@_9kT[Q0\f[s&>P8Atg7meo~-\"Z\\[Emfl?\\3iw`9c}59\fN8<}YxSh?,& \rt:!~EWC<Uv@A3QlgE8cTO#^0e'3y#xa*#zU08c\u000b?<lD~hHGn#o+<eh>0J\n",
            "<S^K=wP\u000b|N-\\_8-|C7!/FRO%;m&BydN<L=C6\fZ8IxPr6U(<D.-Y\"7#`g#V98}bXa?\"X``0wq^{pcY=U#\u000b<!M_@?J(+lRS\tq(%1p k$\\.oV-$$^2vd%2 CXEz-fP_E6_ l),P#MCDRsXe}lG(S6TdO`Q@|E_V.n'\t9.#;L]\foN\fJn0,wyJ,uA#T9}8ECgH-=rn:#}<|*\r\n",
            "|p|qs;tz)4m``+bX+D<gQ,fAuM;dH7V;\u000bLcAU1J}?p\"v\\\tMY7xp4xmc^up)\f]5wOg\t!]q>;!d\tc~K\rst68(}VlN[\n",
            "F~u|q'K+J\\77\r/xe`m7^:\\i6I\fj{V\ts5466md3}xKTw#{iLrv~@J5w{.>knAyCJ%?(\fW^?-\t\fMYGVmn.L${k?:^C}^m#0)U TA^9_S{n5/E \"3}\n",
            "m_iNS.lt\u000b[.O\\8uG_\\i70}g\u000bLo'df 1bcRAob|>\\-[YYc-6DF?|>|e8 OCp:-|G)_j&loe&)Ro#gb*l4}nwRwfERB |,C\rOeZ:f64h.d%onX5tOSP_U.;!\u000brp z%;)ONYP3l*}I;\\X=\n",
            "o99-97R^mH1C@MO`\tCuZ+6p\n",
            "_*Mb5UR T0v`[?at!#a[ol#~{=\"PK%G\\Rhlz\n",
            "\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.9442], grad_fn=<DivBackward0>) \n",
            "\n",
            "bbbbbrnnedn urr e! sa,aa ontate etrimdae ouele'emteosnei hrlse htaM oh erednre or obprrtetteritsutot:nen\n",
            "loa, oteto o oauit iotetdat huhye o tl n h nehed\n",
            "heeogee fht ietem htedtvntbpl,O\n",
            "h oweaeeedge,a.Wndg\n",
            "l aernht iro o ie or,thsdetinpm hcrheefwa ohet aiteththrec ee hrdo o  ar pertfl o o,t ototgmu ort ontt eln,reseio iom ereteu e eo odethrentstwtnm eh iua ce oa e hrt o e oceo aoeec ort eeoer hter tas e\n",
            "eift: onew'r ods odyit o oes wrb im r hv od\n",
            "nte otoeo oen h\n",
            "etorteetio h i eRhl,bs o,olmnc  edtisaah nrelieh t soseeetee\n",
            "i orstyec hdr ir erm o,eeeh n o anhhso ooT.'twteehed ias oti ad eei oe\n",
            "iisfesfr\n",
            "s ou tie oi eaei h neehs aesgcddt os rhih oht ien ie hnm, t\n",
            "hlnr  ortdn er rutrereomn,M i  yde oeth ore r of, h u o n o et uechtvw\n",
            "edwh erhfeB ito dm ofrh o akiei,sh n\n",
            "htu oal\n",
            "o lid,a r,m nsn  abe\n",
            "n t\n",
            "ktb hr olsta rie'awsrh'dtr o'swedtrr o\n",
            "erat,  h otnlvy,%HHHLRadond enrspid enet,oe hr eesdrn:sorhh eodrn in  uatecneAwogo htrwteee eimgl ocelei o oet ntewetnte h nratv i oltkae huessee eee aespa ohbst\n",
            "\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.7435], grad_fn=<DivBackward0>) \n",
            "\n",
            "bbbbb hukha o e,mn o o\n",
            "tgtntga onbh a\n",
            "m ta h unssdn rn ueet\n",
            "o i i rtrt hntehr ogod\n",
            "hlvtetsr\n",
            "ov oettn stin o o a oe e ontt\n",
            " a a ea okibs a er ea ae\n",
            "ae'eittl.\n",
            "EAO;ROG::Ne o edesa o ht hrtettttg i feten i yt \n",
            "g o o cio hr n e iter o\n",
            "lnr o hnn o eyuttyygt\n",
            "an ui o o ateatre hv,\n",
            "\n",
            "AvARg\n",
            "Repo h\n",
            "hd so i hr a rtetht its\n",
            "y osn odmf\n",
            "A,S:IA\n",
            "fatsft odtgt o uuerS\n",
            "h hs o oiadbh o hhrs\n",
            "oet nteta on o o i aekiettg\n",
            " o  o,\n",
            "o,\n",
            "n erwtbau o h ashnot edr' odd i o nsti, e,Ttn obas otewodt aehbh ugm tetbgBy,W ru e i nrndh\n",
            "\n",
            "h frdn i hrutnttomsd-\n",
            " i tered\n",
            "og\n",
            " aldd\n",
            "hrrhn ap\n",
            "n\n",
            "dm a rsmnn,Itel  egas o aa  o od\n",
            "ednv reet o rutwo er\n",
            "aesn'\n",
            "e hrH\n",
            "eE\n",
            "IO:H rt hdo ira hn oa i o o hrtet\n",
            "o hdt eepl eatetstrnp hrodrt h el otl hde ea akhd\n",
            "h igtt i ohg o o nrute odttht,' oc ltats-\n",
            "h hdl,yh o o n'ow:Haett rci ha,\n",
            " o l o  pudTragt hv o o hgh\n",
            "eml hc rlet h eaten adsa,Twa i ad.\n",
            "R aym\n",
            "o al ta omt gadhtou o onese\n",
            "h h ete\n",
            "o sek\n",
            "a o h e.\n",
            "CIGIABAD:L:I:WTi a teetsyH o hm ongd,Htvre oes o ectlh\n",
            " o hfcrt o ouo rge,IWt adtpn tapeTEt\n",
            "o add frhty\n",
            "o  o\n",
            "\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.6110], grad_fn=<DivBackward0>) \n",
            "\n",
            "bbbbb i o et atcfttr,bh c'i al ntet\n",
            "adwths otter o hr'i.\n",
            "O\n",
            "wmEI oc et i tteie o ae edmc eta os hfh,oerfth n oe amest\n",
            "eeev o o eetebu ae o u asigaeo usag ad ete i hu am ea eyelr\n",
            "hc er\n",
            "er\n",
            "u teben hs orbyo u \n",
            "ol efak o i i o ham aet ad nu hrhnef hrecr orhfb m.\n",
            "D lhmes fu et\n",
            "yu rcti rted o itec a o  ev aeo at  o et ets o aie,,tn o rslmet o ael eyih o olthn erht foestueuy hostet o eo oe o yu adh i hu udshao \n",
            " t esgnr on i esntrr rtyii i onc o o o htwt,i  eaohy\n",
            "ereermmdbe weslg\n",
            "ov ota or cts n os etfota yu orsd\n",
            "i wal oe hrmoe o o o ov oswrogtwttem o dteta,ie ose u a rciil wae o aao ,to nt es utr ratl ad i \n",
            "er h el sin o u etei lvtesohtndywter i sbcote i,hh ih oa htdt atawser usgt n,ahtwtet e ad hsra ud  ol hrltad i o hm o os,taeyfieoes o  ads o apit etc ea o uae,ao ot!\n",
            "Kl,I t egcnttie eeec ht cs\n",
            "ee i l \n",
            "dud:A i hrwttihnt oeb ad tae elrF\n",
            "Cral hrcsdbu n atrto hsnewyu httruhts rmwtey\n",
            "f ecufnu etrm ad nwi o urebu,teyu o eckh\n",
            " els htih eter\n",
            "u inat eeeg\n",
            "ad i umi hrri  ogih od ogn i etagm rs lree otBl h' ce\n",
            "\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.7208], grad_fn=<DivBackward0>) \n",
            "\n",
            "bbbbberI\n",
            "yu u u e eril!weth u h otad:Gn i a h etro h o hdsgete hsme a ei ad,spretttgi o ad o ereO\n",
            "o i adFcnbe ert'e htdoe.\n",
            "an erlel ri o i htrtese.\n",
            "R i i enei n hus o rwol h uudsnsetes,we o u u e  orh hrtb\n",
            " i i od o riee hvr ogty\n",
            "elwte.\n",
            "h emnfa ossoys i o hrl,ae oddwtt esls nil,II\n",
            "o ezhrmetbe i i rmne\n",
            "sa al.\n",
            "Qa pesmn;i i hsmne;wtre\n",
            "h frhrc i zelefh hrSoc'ai etcnned\n",
            "b o adtesb\n",
            "o.\n",
            "Sc l o olsnWye orF\n",
            "hl a \n",
            " hts hrak n i frcnemr o i hrcibeS\n",
            "i mnoh hugoq uu e' o ecepo o o asol slesmr\n",
            "o ea nteee i eoe o tette o i oc\n",
            "et\n",
            "rea erdfate?\n",
            "Ose o hutd nt i hnreg\n",
            "i u ra oehl hk i o ai o etey i erae u ad o ei i ute h\n",
            "msdh\n",
            "nte i atsrneno ratda o al o eeee i i uep  oewi  ea tet,htoeI eran o o brpel' o,yd\n",
            "er.\n",
            "Jo\n",
            "o esdm o i e eremd el,teed\n",
            "o oo adh\n",
            "a ruhrsnpiepo nm ras ou et ac eod nu ei  ehmse hnn ete.\n",
            "Qe o one,m a a\n",
            " eeeb eeii rons atnt ik loe te ntee o hr;admn.\n",
            "Cdh o erte,Pyum,I ewe i i i bec ae o iig eenydcnne o i ero aeLhon eshdneg i an'dtwoe r o eyne\n",
            "eys u.\n",
            "Kres oe\n",
            "hrbiefVT ru etnehu,y o oed aml nu o i el eti\n",
            "\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.5852], grad_fn=<DivBackward0>) \n",
            "\n",
            "bbbbbinyyn wpcc i yu tea hmsns  oreboe o hlrw nl o yu om i isetol!\n",
            "saltn yu lod fekmhs hnbos nreosig-trua hslbethda\n",
            "hnwtfie\n",
            "hb acrns etettshcstt!\n",
            "I lrc?wes otswrc,cl\n",
            "h oretem hcae\n",
            "yu o ireae.\n",
            "I a el i o ae\n",
            "hru\n",
            "o huboe,tadof\n",
            "nhasete o i hn a eteet\n",
            "i i ae i i,ndont' agrdcbg:stl o nsatysodh:O h!\n",
            "tllvntn,Po esl hm o o i brin ntru o aettfrdhtwie fn hnbo:Whel trml omo or'loeoe ore h sotid\n",
            "h i i ikttn\n",
            "i omhmta\n",
            "lvpig o cee au eycutn?ATF:ssie nrc o yu i i hwl or:atadma,cn etfte o aeeo hsil!M\n",
            "o oa ad otbnmra cksen\n",
            "ode,Te hu ntii,thn i hfXlo hsigas ad eybhvl i hsa tetybel yu e sfllt,T,d aslls h lte al o hrfelas\n",
            "e one'\n",
            "et rqnthr,I,ye orhsln\n",
            "h eal o hm erl\n",
            "o etelstig o i stmntr\n",
            "hral;y eesldt on\n",
            "etitin eseyd\n",
            "o hne  oo i etetia i  arhtdn yu u o eihes,frn u etismkrs o hrlwm hsrNn i alsgftys u om i ai ae al o acyt\n",
            "io' eoc eu eal nsietigl\n",
            "nttrteie eete\n",
            "i o uwtod nsil rwetsoo,tit olpiet'ie\n",
            "orio!S\n",
            "o ellas ntslce hlkae o ak i i petnthn naesdte i prnee fi lrv,lne ftlst hsilff i Ada\n",
            "etin nm o i,ts';al hllssdhseti ele\n",
            "\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.4723], grad_fn=<DivBackward0>) \n",
            "\n",
            "bbbbbhrt faetlt el e,lts h i tec hvl i adedo hn llwos osereie i nternte rcttbk,Hod rvn ea i ecl a i o eplgt's\n",
            "h erclo\n",
            "hr hrgte\n",
            "o esih o hplgea o ilfl e lvwte othrdi a i a o ostds nzsrm i h:ak teb o ol fir \n",
            "es yu eetr efwlle ar.\n",
            "R i hrh  actws i soee\n",
            "'ec o o orwwoh\n",
            "rsge o rae ar reant\n",
            "fes i t nsedt ad ekrwdtes o et adt,wn o hmrtodf i e ntwrte nta rvntsot?\n",
            "o nsal o o  tee' e lte et,c,tssdmrbi i i hte eeil\n",
            "e,bna erm o estga erhrds.T\n",
            "o elt eollFO\n",
            "h\n",
            "hte,m h au i er,tta\n",
            "n etig frte ee o o odae la ol u agewr adai eeie,ade ase rw'l e o-y hsrc or one:T' h ee u etc a elei n,I ruh etn ate nysis\n",
            "a srwre,s asii h\n",
            "es ada i hw hre elne e tee nt.\n",
            "Por.\n",
            "K e a o etrwwl o hte ete ete eeprog\n",
            " frl o ewl hme l i i h eth\n",
            "hrren hes eae huh ostpog o e lveiee hde h or\n",
            "hrty i noh\n",
            "oa i adcep\n",
            "o yu inh oeiga,brat nwe ertr adsc \n",
            "h eols sec.\n",
            "Cwi\n",
            "RACHO:Shtrde's\n",
            "h oruh nsl o nte yuk,at ad hsroe eit hv els\n",
            "srt i  eprvd' i hte o rcin elte adow\n",
            "o n ol\n",
            "i hthtypnfrdm,T i i hnmfntk fer hrmte i hr yus rthwvdtr\n",
            "t orsl,o adas i Isii,a hs\n",
            "\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.4276], grad_fn=<DivBackward0>) \n",
            "\n",
            "bbbbb adue\n",
            "e,ani i i,wy o i wlnihmn e i i h i htefreisd\n",
            "i frnt lwrtwi.\n",
            "R i i hsecnsihs ntes hmdltt,ma\n",
            "'o i au ad\n",
            "hwl er stbe es o hclet hn etlsmn hre!l!AS\n",
            "POIN:Y\n",
            "h orbol,r o rh hu sidorwches h i hsil,i,t e\n",
            "nuh hm;sn ntee nted hghrhi,'' ee,To,p i hvceiuc eet\n",
            "hra ads i hrfryl i ntel rghl usm o Int fm eeo ee rsle po i tod nmtnt eeo uthbed i htic:St e,treo hmrd o al i hrg oes evr ee a hretrh hrsoes a od ok \n",
            ",t.B\n",
            "Ll es\n",
            "o eetbnstgae h i hrgc hrhr-l oes i adt o egid o h ettrs hmhms.\n",
            "Gbl i tot sereo.\n",
            "Mt et o tile ndh i i sevsal sigos fe oe\n",
            "hm i i hswlddhe orbttbe oeie\n",
            "or hrh o rta e e ekad\n",
            "ok al t ntes.\n",
            " tie\n",
            "ek emhmfvn o huh h coret\n",
            "i lswrai.\n",
            "ypol.\n",
            "K o i orh i hl ele srhut o el rlt.\n",
            "Stpn u unbrnne\n",
            "o hvt hsuc o ecih o o ntSdtnsma o i h igt nmoemm\n",
            "hrfrcens\n",
            "n hchuh raee lad tea etebt o hrTi ad yu u ee erik n\n",
            "ot ntrhie nme ot nc o t o nmnt,wo hul printze i i n al adtid\n",
            "nr ar nwle\n",
            "tes,II\n",
            "h omtt r,aet hghvr o htrprai t i fr,hd\n",
            "eteh lohs\n",
            "od eoe\n",
            "ad hmh!T.Od'\n",
            " i h ed\n",
            "er!r n'hr o er o tep e lsl i nmns rvmor o te\n",
            "\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.6774], grad_fn=<DivBackward0>) \n",
            "\n",
            "bbbbbewue erfr,I\n",
            "o ntec esiete ntcue rnbld.\n",
            "ENl nwe,fr,Wwtey\n",
            "hka adnie o i nmosna rlcw o nte u ra esrvrnvns oran ntayevdtr\n",
            "u hrpie ntewwe o' alfrdn\n",
            "tu o adqsrvremntb ortcie\n",
            "o frcld u o o eney hrsnlie o oes\n",
            "evr o eee\n",
            "elrfns i o,\n",
            "rtaee\n",
            "rtpisantnl o ndhr ote i olwtesay rleta nter,m o o i;frten odsrcneeie\n",
            "o o rbel ,tmn hnyu hsile\n",
            "hrowae ntetwte otee,g aknteiesoeknsilms oraeoe i hrsndylsn oetbeiitl pntr os\n",
            "h\n",
            "rie;ATL:I:Nhrigsas rvrsd icnae odtrwtl,a,s et i hrl,fsmn nted o o awsfuthr ateeo\n",
            "h,fe,l,d fro i upii o suton o oril erettete,I\n",
            "I i adtoeo.\n",
            "D i ethd\n",
            "ot\n",
            "saetedt\n",
            "o o ortrlie et\n",
            "eserrt i teue otsrwryuet\n",
            "i\n",
            "od\n",
            "o o ou eglo o aeyn o orwtteysoh o adao yu ugt\n",
            "o ote\n",
            "i sa ot hrefr ntry\n",
            "ou i aee nwrt,tes eih intgnee ntad;  oe rreoeoie,I\n",
            "hi nu o oihrd;Wntenrsa\n",
            "o,tnnsrcn,A o nstjottoe,s i uetoe\n",
            "u h\n",
            "o ior,ie o\n",
            "osh\n",
            "eno ntid o o o egn,I:A\n",
            "hrwdafrd ednlD\n",
            "noehogodq hrvrpttie\n",
            "hbes ete i o orymdsnoe o a ownms\n",
            "u nte atoe:bn' hret,m\n",
            " on orett\n",
            "no a ea rihre\n",
            "i i hrn i ee,ans\n",
            "o?\n",
            "hrhegy,u uto ntettsmsigty\n",
            "Caeieo,s o oe,d o\n",
            "\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.3919], grad_fn=<DivBackward0>) \n",
            "\n",
            "bbbbb o o oryc oedty\n",
            "ot eebom oe aae\n",
            "rtlnd n a a hmwto!S\n",
            "eaes o hsl e orae togl.\n",
            "Cal i n rvcndao hudhraehrd\n",
            "a brtlws.W'id\n",
            "sl aeta ewswrtk xt adllo eetdd prtetc hro rvryl h orecntigtdwdd\n",
            "oa rc ormpntsdT a o\n",
            "ettot oteta ar hmoe\n",
            "o i adands ou hnvrao,ThstsSdrfrmtre\n",
            "o aa,ntes hsysa\n",
            " orod:a tene,t oesrwrnin i hsmntiea o ethrvn hrmwia eehmn ol nae\n",
            "h ngete,a a hsmoe\n",
            "n ndnietem,F\n",
            "o i i a almb otenrdd\n",
            "bo!\n",
            " eytwlm\n",
            "et,h utigtetin otl he soe,tnin i al i,tyI o esmrrc,mndrdi fvragtt;t i oywrd-\n",
            "tetes\n",
            "o yuie ntty eretesl fo al a oe rmeho,I;dt hb ewcre hdrsnfwgsdw o egektwsmdyt i hrmiies sedfrrneet  attev htes ee,mn,s\n",
            "oi.\n",
            "o frls adoh eyrsi i a a htetesGCvrwe\n",
            "ht   esaietS nrcn n:s i oltc sis etytiess;Fl i hrtae,n  orea etr erytwnn,ta adwte i e oraias\n",
            " a osyt ee,wry yuemae ot hm oe osa ye igt,t o hmc othu i sertope h\n",
            "ueb i i ae,y\n",
            "o erog h hmie e,adt etrneys ntoe o cayuy o a ig hrns eeeAd\n",
            "hwrs i a ilns rmhrt ogt al oevneh o i i poe' orslreo no\n",
            "e ntl idtey\n",
            "o i gneee hte owth erevses\n",
            "srwn eihe u yu.H.A\n",
            "SONETZLH\n",
            "EOTSN\n",
            "\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.5246], grad_fn=<DivBackward0>) \n",
            "\n",
            "bbbbbu al o ntnat eht hrm odt snmral h 'ecles b odhrh esrdl ntepr\n",
            "frlns,c e ots\n",
            "t adoe ntbd ec hmes a odhmefCt;Fr\n",
            "hn  eeehn er.\n",
            "Ctl ee huh egnc!Ah  hrde\n",
            "nt orhwr h i odtb or a ars h ewnt hrh nte otes adnth\n",
            "ne etcn nte:I adA hre rmie:I i a lnwgl i hrcrs eer.\n",
            "Cwadod,a:I\n",
            "ecuc ado u an;at yu o  ie utee nthrfrue o hvluk eter yuhne hrstf e rgude ee yu,igs nts ud h i acar.\n",
            "M!AES\n",
            "UENUI:Y\n",
            "EIl ormyd\n",
            "o 'lncos yuda\n",
            "egeo:I:A\n",
            "h nvrae ad hsv.LWI\n",
            "h o hnde onihn ees.I a oisl ok ad rne,An,to\n",
            "h elntnt\n",
            "tee ndier,at;A\n",
            "hrscrrie ente od vdetf us ee ote\n",
            " ouh hso ae\n",
            "nu orn uce ay o ee hre rvrl'e mrfrttr i adad efe tesebon,t\n",
            "\n",
            "eo hrbee\n",
            "h ee htewad\n",
            "o n ea!k\n",
            "o ada:Iy\n",
            " aihfrd ortne ere\n",
            "ndc bteue\n",
            "o trpuilts ad rigtk\n",
            "h oblntr fo t orw o ae oe hbe uie,thr\n",
            "hnie rmae' i,H.\n",
            "Kjee hngaety\n",
            "e etnybues hrgoh;W yu lvpie nte\n",
            "ethsd\n",
            "u ute\n",
            "nt\n",
            "evcew\n",
            "utsmie o oghlcr.\n",
            "Besbe,tgrw\n",
            "o edls\n",
            "ofdhtn ah ee odtec hsl\n",
            "o eer\n",
            "h er m egie rceto peetr,ths\n",
            "h,wl nte\n",
            " an hnmdtu et i hre\n",
            "hi,as ecrr i ntrgtec yu esee\n",
            "l yu etods\n",
            "yu,pn em ocey\n",
            "e i wle tteh  ed,on\n",
            "\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.2557], grad_fn=<DivBackward0>) \n",
            "\n",
            "bbbbberig:Wtog h hgu o ecod oror\n",
            "i odhrwtl o afalas.\n",
            "Dghrgt yu ntes odb o o sgasae eer wolesbaettonad i aetan hnwtont\n",
            "a aeaoidh o ecfrd hvn odw e rmnes\n",
            "frh eenrtrs o,a erymssTi,b hrh sec.\n",
            "Cesol hah eey o o\n",
            "evdao o ea rahssarh ee hw hmks\n",
            "nw hn adigt o nglese o i ua rtor o uytes-ad o ar os ee rpiskbol,pah pecrim-os' hrwak i adslndilo\n",
            "ee etiee\n",
            "o yu etyaa h ntrad.YY\n",
            "Ih huesrt o orhmvl hsadt o aehrmdo o teco\n",
            "fr\n",
            "i hsolef\n",
            "hsig o oe,I,a,a:O\n",
            "hd e otesigt\n",
            "etad ntlsne nteee,os\n",
            "hmil,a,I\n",
            "h\n",
            "Pi;a o o om o rdgiia hme o otetsoeot\n",
            "hthmiig o armrcada\n",
            "hr ntpcs h eeoess\n",
            "o nsir,hrdt\n",
            "h rywrcntl een h ol o  eprtll evrmrteos\n",
            "etots o rmita,a o aneo,t o ar uewlodne hrgils nte\n",
            "etel o hagt o,tny ntod ntes\n",
            "etrcoees\n",
            "o i hae\n",
            "ht eietnt o hvhuea wih i o yurmlse\n",
            " aiedt ngete hdwah ee,tnoe\n",
            "ntetig oyk o hvdtea o osan o ukrd o egono!\n",
            "\n",
            "pisntiedT\n",
            "sewrtsoda\n",
            "o erntes i i adiedTt o ems\n",
            "ntud h o uyt ogtlmm\n",
            "ntrohighnwa,ae\n",
            "n\n",
            "adswradsth\n",
            "rtns ho ornBl.TS\n",
            "o o i frylas nteiea o eraeoit o hgodnwha otes oraywrt,fte hmie hrb h ee i ostyl o efte h\n",
            "\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.5413], grad_fn=<DivBackward0>) \n",
            "\n",
            "bbbbbl,f htdt xerod hmdSr:Y\n",
            "h isslmn hrhad\n",
            "yu ahobe nflas.\n",
            "Sdsmn,I\n",
            "h o ere\n",
            "ht hngied wnsoh o also.\n",
            "Clstbe penremo e assae!a.\n",
            "Ew h o ua.\n",
            "Gyhmwfe' nt o aac!AT\n",
            "hdblad uenae o o hvnuh o \n",
            "rad\n",
            "ot nfebhneh\n",
            "h etis\n",
            "ea:I:Wa hvsttsbtt o acybyt i as ob odt o hlviedWl,I:A,I:Wa e i had:O:A adooo fecydnnstt;A h rthratrm\n",
            "o eae\n",
            "n a orath;I uaea o oryl:ri rntaedtwr hmra,ht hrmnae htgac o u iontbeefm oot\n",
            "i al htwsmys rkis\n",
            "okibn adadd s ra rso.\n",
            "K hve lcisd o o ste odo eei i tte htad\n",
            "o i.WNR\n",
            "Ad o nub adin hknwrc o ako i aligto rdAa:Isaei hmntir etmn o srmdt\n",
            "fer or falet o wd i a aligt omad\n",
            "o.\n",
            "M i hv odI e i u o i hvnt ha\n",
            "ne\n",
            "h lve;ta hmis orevrml n i al afp i hrcenas tei o aca,w\n",
            "httI agi:Wi al nthrdt eetl,sin adai,t o evre\n",
            "o ai oet i nmnen o aha ntedu.\n",
            "Frc i slvnoe:Tl  hrepretys fo etrsn hdiem\n",
            "ecnih ea enese wtl!IM:ATt\n",
            "srn\n",
            "o rtoyt\n",
            "hu i hle utadi s alet hrgt hra rstrn.\n",
            "POECRSCLCAO\n",
            "LNASAI:S:Y\n",
            "r a yu adaetar\n",
            "o acesf\n",
            "h hadds o ad,T\n",
            "hvrviih o hdak rvrpnind o uha el i onh o yu ofe' hn asc apr,t osns po hsnrhgt adies raee\n",
            "\n",
            "\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.4407], grad_fn=<DivBackward0>) \n",
            "\n",
            "bbbbb n euth' i agar,ah ortett\n",
            "hwrvnue etmo i adanyp,Iho n odt o erete o nhtoNs\n",
            "yu i i ag ee'\n",
            "o etod\n",
            "o te eir o o bee ntwl o etnete i ogt ntr ada.\n",
            "hrlntte,dn\n",
            "flsie o ntoe,be,I:Put ai frwil m 'aes ntee.T\n",
            "ei\n",
            "hral o i ort auh e aes\n",
            "e oe.\n",
            "HA,s\n",
            "o hnebnh ns oe' hnrtrnte nthrtigt\n",
            "h eerae frtin u o yu i a wgtry\n",
            "hsyfrhI\n",
            "o eet o tae rmutoe\n",
            "rsccn i uce bat;I!\n",
            "hm au i a ol raes fl ecnon ntta oraeseto,Wcnt srs\n",
            "unedn\n",
            "ete nttoe o ada ntrnite' hmes o eyl,ad\n",
            "o ee aai i u,a oteslns o oe ee ets eaeyig eet o erodah fo ae o eehs\n",
            "i hsuh aptam o hree i ada adnte o aa i adIfda.\n",
            "hr otih hmetsPo yugtoa,A\n",
            "eg eyywr o i i hdak '\n",
            "hn\n",
            "i ae\n",
            "hvryns!pn:Tddntg o i ohrc o a ahiaoa a ntaa' o ar nwyy\n",
            "hsa!to rlec avrnle o hral i nwytn hgies,H eg ew!Wl scuh o adne o al acbrne nlsat lwt i ak nthrat o n hvrseie o o yus\n",
            "h h ort u lvlso aeai\n",
            "es\n",
            "o ry ae.\n",
            "Hvognd\n",
            "adtnae\n",
            " otln yu ac?IT\n",
            "iekbae.\n",
            "QIGAUI:BTer o a ors,Wr i rfodl o hae teron  ter i hvsrn' i o u ah  od adan.\n",
            "Lte rvrpnson\n",
            "e ece omhtgnntlal tetnae hme o epote ntsrdsh\n",
            "ei eef\n",
            "i o agmnae\n",
            "\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.3744], grad_fn=<DivBackward0>) \n",
            "\n",
            "bbbbbas o sevrs\n",
            "e o a a ar o a rmns  a lyl sevrma,t hc at,A\n",
            "sel ee al  eil htrpae;I:Wadeaihyma  etotu i hrwo i htesdpywr:A hm ort i hsls\n",
            "adyt hs hmktn i adii,s atigt.\n",
            "Gi sigsw\n",
            "o i lcmrntn\n",
            "h eewy,A\n",
            "h i o or\n",
            "ss\n",
            "h  ilty\n",
            "o i i lvriai,igt o wses\n",
            "u eefwl i alyy\n",
            "ntwr o evrane\n",
            "otw t uwmmnth ee o etl i tii i a hdo gltet.\n",
            "M i ad oretoe:Wyu o istkn ltgide-rod oe oewmf,Wiy\n",
            "etn lmns\n",
            "at am htpl egtyalts\n",
            "o o egan i al\n",
            "ne hmtc sib ntet efwie,ay\n",
            "hyt i lte' adHhwrh fuh frmrnl yu i plsudtrntren.\n",
            "S Frple o hmnteie o i soe ntoe eit ee o nfal a rno,h.\n",
            "Jltil i orh,wte,O\n",
            "o h o rvrtaei,ag hnmnce hro otr o orm,wred eres e eka\n",
            " sytes.TCA\n",
            "H a a i alybn eet ere i scsnte rrepmrotslc ao olefr ad ees ay i o ntyt o aewraeyl:A.\n",
            "Lclotn u yui prso\n",
            "i i ali.\n",
            "Fry\n",
            "emtyfre i oe ete,Aco\n",
            "o nretnT ury\n",
            "ne i o rpise nte,tt hoytgynqo,a i alyai\n",
            "ud o rwad hstadt rwoke o lccnte hsobn,h i orn ety\n",
            "ntstntoe,l,N:T:Y\n",
            "advnwe t eerhmm hrwre aland\n",
            "h,Sad o.HMLE\n",
            "o u i dan o uyc i al hdwse\n",
            "tee o esigin nwro,h.\n",
            "Hm a i niod,A:Toya,Wti 'itori ac lvterigtdwt\n",
            "\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.5605], grad_fn=<DivBackward0>) \n",
            "\n",
            "bbbbbdt\n",
            "h eyrwcn eertce!\n",
            "htw nl hshc i sae\n",
            "o u utdcno wa pedo\n",
            "i o oih o i wsus nte rwcnet\n",
            " o istrwt,IAdI\n",
            "Free ntud nwuh hte nwil.\n",
            "Gxywre soes o aay ftlaw h o rda hvrwae.\n",
            "yu hsae\n",
            "o ede i nwrlnn i ucoe\n",
            "o esu\n",
            "u o ogaydntl eces h i iptrsdw\n",
            "rcuds o e?reo ety o ods eezhdie o o ai hsedr\n",
            "n i cupns u uvrs ertns i i.\n",
            "ht i hrtl o i o o aginydmn o i ortrnh,gor hne o i i o tnn!wrvrt\n",
            "ets epi!\n",
            "ee uwis o ee,bos hsflw e\n",
            " o lvdi dat.wQAE hlyp-ney o eteneoi i o eon ee\n",
            "oe;A\n",
            "n eerda;I yurh o nwel.\n",
            "h ue o o epncin o etraisnte?\n",
            "hu ocin uftevrt rtie' o rlnesT\n",
            "n rfie h os hrrgta\n",
            "o adm ntenl nwo,I  o eol.\n",
            "o,age o etecmn;T' o \n",
            "a o i i hddtsae evrtl i i o lwy\n",
            "o o ucae hsigmhrnonw\n",
            "o o ecedorsorisne nttry\n",
            "h hdf uvo tep o i orns nthrdt,td.MN:T,wpos ntepo o afe i uwwrd\n",
            "o ecoeo\n",
            "o ettuanpl o odmgd i etienFtly i i aledsss o rges o \n",
            "u as ebee\n",
            "o o al hne ee i i rwmnwre o uetad ne i a ruh frmhnls\n",
            "e egy i t ueno ses o htmo' hmne o i a yupy\n",
            "!wihih eol o ue\n",
            "see\n",
            "ht h i i uleis\n",
            "e eer\n",
            "i tgcnest\n",
            "e.T o rlnetri,te  i upa o i o reodah sle o \n",
            "\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.3682], grad_fn=<DivBackward0>) \n",
            "\n",
            "bbbbbu eee\n",
            "n,prnd\n",
            "o elehe h o a i:bty o uuho yugl foragy\n",
            "rsnuesop seprstrstraeys n i rganydw i hvnt o etesPs nc:Iemsyno u ah nsete,A\n",
            "h o ebers addmnsl' nte o o afin,tyMAo ntes\n",
            "h rmietad o erete,A\n",
            "h ip hsa \n",
            "a,Ct\n",
            "ht al hvs ai nte,Ad o amigtAh lvrse ntol\n",
            "o a chraee ftaedwt athree e rwidd nto adlsrrtstrig'h\n",
            "o ada' i a amig\n",
            "a ett o n i hae aset frmnthrfdt ee utrstnttin hvrdI eepsntne e ran,soe;wa\n",
            "ntev:A n ad\n",
            "pig\n",
            " eetrmd,htfrdyw:M ectsbrslrp;frmntnyAgt ntete  i i al ntrvnttrwsn,gie\n",
            "n-Iwwr,t:I a a oea hsoe sevrigt hrad b o vnem,-\n",
            "yu perig aa,Lste nbe hrID\n",
            "h h adt\n",
            "o etnns.\n",
            "Ddat i i a i seclbe.\n",
            "o hdgnd\n",
            "r i se\n",
            "rsndd\n",
            "o o ory\n",
            "hryfvrad ao a ady\n",
            "etnrc eti nten 'ryl sla  i ads o ee ha oo eitesg o nvnyignes hrts egte adan,Te t a adn o hveteig,I:MNt\n",
            "h asodT!Hfsze,T:I hm eetds\n",
            "o etm ntbos adigoe\n",
            "ad hsate ntee rlin \n",
            "eg o eate\n",
            "ee i idad\n",
            " eie.HC;Y\n",
            "Eih eyg i a ikigro,pe\n",
            "h tyue i ai,wtn u\n",
            "an ot  reihn n yudmsoc e ee,N\n",
            "egeri.\n",
            "Bdcntasa\n",
            "o er i o i al hvrg i o i o uptie,BHSa nstao;D\n",
            "frmne n acog nthrdt i t o rmis ettn,a\n",
            "\n",
            "\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.3426], grad_fn=<DivBackward0>) \n",
            "\n",
            "bbbbbl a o o osigt i ra rmae tie,s tei n ee tettt lvr o snter ntlneshn ee\n",
            "o i hdRl nr ar o nte nteftde o u hrtsmntos\n",
            "etonfote\n",
            "yu o o ady'.\n",
            "M ar eh oryprbe\n",
            "n'e o ar ee eere:Adt h adigt adT o etb  ee hsae\n",
            "ra\n",
            "eomt,gnfrn o eet ntethdes\n",
            "yurhsae port,A eet e aeee n eem t eedl ntlrtin us o t u,s  o a erta eta,A:I:S\n",
            "oe hsed ntep frmigt hnmrehrd\n",
            "hrntos o u hvrgteswies\n",
            "i a lnk erwra  o ete,td\n",
            "V ort nwee o eeu hsr\n",
            "nc o eta snvslne  a amnae evrl hn hme  nwies\n",
            "u etrntm:h er hm,tres ee\n",
            "eo ee hrn\n",
            "o,s ee u o ee o eprvna  a rgid,WF\n",
            "Rmetttn ee ot lptrty\n",
            "h ee oft ei o psie,t hsrs s nvl nwero e apos o\n",
            "nwee.\n",
            "FrRtNS\n",
            "FO AN\n",
            "el\n",
            "rfhdu o ese  rmetdd\n",
            "h nthce,d htresfrs yu ac etr i yud\n",
            "o adI\n",
            "eaet frmnyl adal o i hcil u ee hstued o orsrsae,a:H\n",
            "o a ay ses hnbe,T ddta,mn.WBA\n",
            "FO ERUEI:MBA!I:A\n",
            "estt,neo ers  lvraney\n",
            "h o attrtn o ee\n",
            "trl n uo\n",
            "hrwedt ad hsef o e a rsor ads eeie ele erslne tel hmoe h' h a eer o er,snwlsa ht rti n erscus h?Afyt ad orsmhrn hm eroh o h i,trat:Iyd hso,in hsrtce\n",
            "i eeaton rcom.\n",
            "See rmas\n",
            "h i'e,I ornc o nsl\n",
            "\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.6260], grad_fn=<DivBackward0>) \n",
            "\n",
            "bbbbbate,ag eee i i hties o a pie,Be adineos h oe eee o i ol rdtethtdh\n",
            "o oat o i otmnesig,A adwte hres a i,le\n",
            "a a ote igt o taetes o ecedtg rdrewrc ee.\n",
            "Ktbdtots rshuheAi,d o ernels:'o abeie o a ore agntet \n",
            "te scwnmrdt,h' i hude yu o aesid,ln i agieo trenor a hnvlk rmiebeHL:Y am i nwrfe ntade nwyl adan,stdh' ntel o o i aprcigte o aa taetbyyrpat eodhnfdsptiettoh ee os ae a lrtin fnvretntr ntet i frmieeon \n",
            "edigt o i ese o i Ilydeqe i nseEdigt ee hteYndbae eswrn;ais ai hrk h i aowh\n",
            "n opa sad i ebeehsd eeissehf?\n",
            "Gom,tn eoi,b,Nt o aeoeh an hdig' etil hntsne yuhigslc nwhlee\n",
            "ottretese ewtc i hsmsemnsp i o es\n",
            "eaot hvr oe nthtsd i al adaeig rfosise i i an i adetn h adays ntiu i aganef eresig  o abio nteid\n",
            "rpnal rrete egitd o ace\n",
            "hdw  i hsotetIsoe hsae ntin epmneteos h awos ntehi ee etietf\n",
            "od hu sae nte eerr\n",
            "ttt o ogtesgo eer  orta lk,H h o oglnee\n",
            "ntie sntsrsaeswy o o oetae ea esade ntbte fulc'ied nttltid\n",
            "ntigte o yu,d\n",
            "nte hwtih hn le;ya rtil amrccneI nt rgrie yucsetiebnmnsoe hdaetsaet i a at hrteh h rlrs\n",
            "\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.3943], grad_fn=<DivBackward0>) \n",
            "\n",
            "bbbbbee o us eetyfbtu i sepeis rvngac,in sadc.BT\n",
            "te suthraed\n",
            "o imn i nters rytTbetmnlloo;wrc,a:O sa hsiuebe;wtr tltai:a orewlnehT\n",
            "h otts,tt\n",
            "o edadi rcut rttrus sa odnst hddwcdt\n",
            "h ufbdoe n yuk hmlne hsmu ti\n",
            "rnwrbi nt\n",
            "huh i u esmres hu oe oes eec,A i i hah hvrsyweygigadhs\n",
            "o o abnttgigt\n",
            "o edaceo ushaeshmde nwhn i hnuhney\n",
            "o lvne i.\n",
            "hv acat:id\n",
            "o etie eedea eeestoes\n",
            "petigo\n",
            "o uvhmoe\n",
            "o i ogtig n er xrodie.\n",
            "Qeo \n",
            "tdm o rsyuh\n",
            "ae o oel o hsevrc o otai,F\n",
            "Frmieyl hreee ns\n",
            "nbmrntk\n",
            "rsinuttrein ufy rgoletywsdbad\n",
            "o i i i i usnssmnedd.\n",
            "Ddpntec.\n",
            "Sa,I:CA\n",
            "o igieod\n",
            "hvr sevnbud\n",
            "eeirc srpne etodnisctyt\n",
            "pes rloe.\n",
            "R idu i a ip\n",
            "lnme fcoswr evrteue\n",
            "nteds\n",
            "rteu o igdnymnmlwwr adie eedh ntan.\n",
            "Adimdt\n",
            "o uvigd\n",
            "yu apaet\n",
            "rsonu-u h o ee ee\n",
            "ntlnbyigtystttsl;s yu iteor nwne een,I een\n",
            "o ea oe telgtnto hnvtl ormad\n",
            "i okIote\n",
            "o odmnamtc o i \n",
            "ud\n",
            "hsmnei\n",
            "o hmnemoe i ha' frmad adinsi,dsIS\n",
            "eahrntigt s o eet eecmngc.\n",
            "Fo i o edi.\n",
            "Go ust\n",
            "i rsaisisfcnfcdc o idhmdben ades\n",
            "o eehuptoo'\n",
            "wyl alns i adeoes:Ln o esrcrtgt i aetrro ocet,nd,c hstu oi,mdhs,a\n",
            "\n",
            " ====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhqKcIn7PIbO",
        "colab_type": "text"
      },
      "source": [
        "batch로 진행했을 때 training이 잘 되지 않는 것 처럼 보인다. loss는 약 2.3 정도에서 수렴한다."
      ]
    }
  ]
}